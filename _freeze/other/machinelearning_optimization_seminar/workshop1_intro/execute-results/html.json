{
  "hash": "64d6fe59d484a2ade084962fd596bb9c",
  "result": {
    "markdown": "---\ntitle: 'Introduction to machine learning: set up and basics'\nauthor: Connor Robertson\nexecute:\n  keep-ipynb: true\n---\n\n:::{.callout-tip collapse=\"true\"}\n## Other formats\nDownload the workshop as a Jupyter notebook <a href=\"workshop1_intro.ipynb\" download>here</a>.\n\nOpen the workshop as a Jupyter notebook in Google Colab [here](https://colab.research.google.com/drive/1rG9j0eWVt4ORoNcEKa89ccnZmYBLeDYb?usp=sharing) (with your NJIT Google account).\n:::\n\n\n## Overview\n\n### Machine Learning and Optimization Seminar\nThe goal of the Machine Learning and Optimization seminar this year is to expose the participants to topics in machine learning and optimization by:\n\n1. Facilitating hands-on workshops and group discussions to explore and gain experience\n2. Inviting speakers to introduce machine learning and optimization concepts\n\nWe are excited to get started on this but recognize that since neither machine learning nor optimization are standardized in the department, each participant will have a different level of experience and exposure to the different topics.\nAlthough this will require some additional work on the part of the organizers (and additional commitment from the participants), our hope is that this disparity of experience will increase the collaboration between faculty, students in any year of the program, and even visitors from other departments.\nWhether you are a participant or an organizer please take the opportunity to share their knowledge and experience with one another openly during the workshops.\n\nAs a student run seminar, we also recognize that some participants may have expertise beyond the workshop organizer.\nIf this is the case for you, please engage in discussion of the material during the workshop and give feedback after.\nAll the workshop material will be available online for later reference.\n\n### This workshop\nThis first workshop is mostly focused on tooling and the basic concepts of machine learning and optimization with the goal that everyone can be prepared on the same footing for later workshops.\nIt will also give each of us a chance to get a view of everyone else's perspective, interests, and experience.\n\n## Your programming environment \nIt is safe to say that Python is the language of choice for machine learning.\nThis interpreted language has a very clear and high-level syntax, is extremely convenient for interactive programming and debugging, and has an enormous user base of enterprises, researchers, and hobbyists who have built an almost infinite array of open-source packages for every topic.\nIt is exactly for these three reasons that the workshops for this seminar will use Python.\n\nSo, to get started, we will give the basics of the Python programming language. \nJust kidding!\nThat would take too long.\nWe will instead guide you on how to install Python most conveniently, teach you how to get started learning about Python, and then point you to a curated library of much more high-quality instruction for using Python.\nA list of some such references as well as documentation for setup and important Python packages can be found in the Appendix [here](#python-resources-and-packages).\n\n### Setting up\n:::{.callout-tip}\nIf you are looking for the easiest and most immediate way to get going, check out the [Google Colab](#google-colab) section.\n:::\n:::{.callout-note}\nThis section will require use of a terminal emulator for installing and running Python.\nIf you are not familiar with the terminal, check out [this quick tutorial](https://mrkaluzny.com/blog/terminal-101-getting-started-with-terminal/) to get started.\n\nIf you are using a computer with Windows, the terminal instructions may not apply.\n:::\n\nPython is installed by default on MacOS and most Linux distributions.\nHowever, it can get challenging to navigate between the versions and packages that your operating system uses and those needed for other projects.\nThus, there are a variety of version, package, and environment management tools:\n\n- **Version management**: Which version of Python are you using? Can you change versions to run a specific Python program if it requires?\n    - `pyenv`\n    - `conda`/`mamba`\n- **Package management**: How can you install the many amazing Python packages people have created?\n    - `pip`\n    - `conda`/`mamba`\n- **Environment management**: If you have two projects that require different packages (or different versions of the same package), can you switch which packages are available depending on which project you are working on?\n    - `venv`\n    - `virtualenv`\n    - `poetry`\n    - `conda`/`mamba`\n    - many more\n    \nThe `conda` package manager is the only one that fills all three roles.\nIt is formally a part of the Anaconda Python distribution which is a favorite for those in the fields of data science and machine learning.\nMamba is a newer and faster rewrite used in exactly the same way and which is highly recommended.\n\nThe best way to get started with `mamba` is to install `mambaforge`.\nYou can find installer downloads for Windows, MacOS, or Linux [here](https://github.com/conda-forge/miniforge#mambaforge).\n\nFor Windows, run the `.exe` file once it is downloaded.\n\nFor MacOS and Linux, open a terminal and navigate to the download location:\n```bash\ncd ~/Downloads\n```\nThen run the installer as follows:\n```bash\n./Mambaforge-Linux-x86_64.sh\n```\nThe installer will walk you through a few steps and end by asking if you'd like to \"initialize Mambaforge by running conda init?\"\nAnswer yes to this and restart your terminal.\nThis final command will have added `conda` and `mamba` to your system `$PATH` variable, which means it is available to your terminal.\nOnce restarted, run `mamba -V` to print the version and to verify that the installation worked.\n\n### Environments\nThe idea of a `conda`/`mamba` environment is that once an environment is created and activated, all new packages added will be added to that environment and will be accessible to any Python program run while the environment is active.\nAs an example, let's create an environment called `workshop` with a specific version of Python installed.\nThe following will create the environment and install the desired `python` version:\n```bash\nmamba create -n workshop python=3.9\n```\nOnce created, we can list our environments via the command\n```bash\nmamba env list\n```\n```\n# conda environments:\n#\nbase                     /home/user/mambaforge\nworkshop                 /home/user/mambaforge/envs/workshop\n```\nNote that there is a \"base\" environment which is where `conda` and `mamba` themselves are installed as well as their dependencies.\nThe best practice is to create an environment for each of your projects to minimize dependency issues (when packages depend on other packages and sometimes require separate versions of the same package).\n\nTo activate our new environment:\n```bash\nmamba activate workshop\n```\nRunning `mamba env list` will now show our active environment via an asterisk:\n```\nbase                     /home/user/mambaforge\nworkshop              *  /home/user/mambaforge/envs/workshop\n```\n\n### Installing packages\nNow that we have an active `conda` environment, let's install some common machine learning packages in python.\nIt is as easy as writing:\n```bash\nmamba install numpy matplotlib pandas jupyter scipy scikit-learn scikit-image\n```\nThis command will search the [conda-forge](https://conda-forge.org/#page-top) repository of packages and install the most up to date versions.\nHence the `forge` in `mambaforge`.\n\n:::{.callout-tip}\nEither `conda` or `mamba` could be used for all the commands discussed in this section.\nHowever, when installing packages, `mamba` is significantly faster.\n:::\n\nNow that these packages have been installed, we can easily use them in an interactive `ipython` prompt (installed with the `jupyter` package):\n```bash\nipython\n```\n```default\nPython 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50)\nType 'copyright', 'credits' or 'license' for more information\nIPython 8.4.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: import numpy as np\n\nIn [2]: import matplotlib.pyplot as plt\n\nIn [3]: x = np.linspace(0,10,100)\n\nIn [4]: y = np.sin(x)\n\nIn [5]: plt.plot(x,y); plt.show()\n```\nThis should plot a simple $\\sin$ curve.\n\n### Cleaning up\nAfter we are done using the environment that has our desired version of Python and the needed packages, we can go back to our regular terminal by deactivating the environment:\n```bash\nmamba deactivate workshop\n```\nIf we have somehow broken our environment and need to remove it:\n```bash\nmamba env remove -n workshop\n```\nThere are many more commands and functionalities that `conda` and `mamba` provide so further references can be found in the next section.\n\n### Google Colab\nAs an alternative to the entire procedure above, you can use an online [Jupyter Notebook](https://jupyter.org) service hosted by Google called [Colab](https://colab.research.google.com).\nThis service will get you up and running immediately but cannot save your environment between notebooks.\nThus, if your notebook requires a package that is not installed by default, you will need to add the installation command in one of the first notebook cells.\nFor example, to install the [reservoirpy]() package, we would write in a notebook cell:\n```default\n!pip install reservoirpy\n```\nIn a notebook, the `!` denotes a terminal command.\nThe package will now be ready for import and use within the current notebook session:\n```default\nfrom reservoirpy.nodes import Input,Reservoir,Ridge\n```\n\n\n## Basic concepts of machine learning \n\n## Warming up\nLet's use what we have understood so far to fit a simple \"machine\" to some data.\nGiven a prescribed model form and some data, we can fit our model using a simple gradient descent algorithm.\n\n### Gradient descent\n<!-- TODO: Come up with simple model in which parameters are non-convex -->\n<!-- TODO: Simple overview of gradient descent -->\n<!-- TODO: Simple animation code to use to generate plots of parameter iterations, should work formomentum version also -->\n\n### With momentum\n<!-- TODO: Simple overview of adding momentum to gradient descent -->\n<!-- TODO: nesterov acceleration https://www.codingninjas.com/codestudio/library/nesterov-accelerated-gradient-->\n<!-- TODO: RMSProp https://optimization.cbe.cornell.edu/index.php?title=RMSProp -->\n<!-- TODO: ADAM (combo of momentum and RMSProp averaging) https://medium.com/analytics-vidhya/momentum-rmsprop-and-adam-optimizer-5769721b4b19 -->\n\n## Conclusion\n\n### Future workshop schedule\nTo keep your interest as we begin on this fairly generic beginning, the schedule for workshops for the semester is planned as follows:\n\n## Appendix\n\n### Python resources and packages\n**Python**\n\n- [Python documentation (especially sections 3-9)](https://docs.python.org/3.9/tutorial/introduction.html)\n- [Quick cheatsheet of general Python knowledge](https://www.pythoncheatsheet.org)\n- [Quicker introduction](https://learnxinyminutes.com/docs/python/)\n\n**Conda/mamba**\n\n- [Conda user guide](https://docs.conda.io/projects/conda/en/latest/user-guide/index.html)\n- [Mamba website](https://mamba.readthedocs.io/en/latest/index.html)\n\n**Essential packages**\n\n- [`numpy`](https://numpy.org) - Creating, manipulating, and operating (linear algebra, fft, etc.) on multi-dimensional arrays. A list of packages built on `numpy` for a variety of domains can be found on the homepage under the _ECOSYSTEM_ heading.\n- [`scipy`](https://scipy.org) - Fundamentals in optimization, integration, interpolation, differential equations, statistics, signal processing, etc.\n- [`matplotlib`](https://matplotlib.org) - Static or interactive plots and animations\n- [`scikit-learn`](https://scikit-learn.org/stable/index.html) - Standard machine learning tools and algorithms built on `numpy`, `scipy`, and `matplotlib`\n- [`pandas`](https://pandas.pydata.org) - Easily represent, manipulate, and visualize structured datasets (matrices with names for columns and rows)\n- [`keras`](https://keras.io) - High level neural network framework built on `tensorflow`\n- [`tensorflow`](https://www.tensorflow.org) - In depth neural network framework focused on ease and production\n- [`pytorch`](https://pytorch.org) - In depth neural network framework focused on facilitating the path from research to production\n- [`scikit-image`](https://scikit-image.org) - Image processing algorithms and tools\n- [`jupyter`](https://jupyter.org) - Interactive \"notebook\" style programming\n\n### Julia as an alternative to Python\nJulia is a fairly new language that has been mainly proposed as an alternative to Python and Matlab, though it is general use.\nIts strength and its weakness is that it is \"just-in-time\" compiled (meaning your code is automatically analyzed and compiled just before it is run).\nA clever language design combined with just-in-time compilation makes Julia as clear to read and write as Python while being much faster.\nIt can even approach the speed of C when written carefully.\nHowever, the just-in-time compilation and type system remove a chunk of the interactive convenience of Python and its young age also means that it does not have the volume of packages that Python does.\n\nNonetheless, it is an elegant and high-performance language to use and has shown rapid growth recently.\nConcise, simple, and easy to read and contribute to packages have been quickly emerging and it already provides many useful tools.\nAs a result, it is worth describing it's installation process, environment management, and noteable packages.\n\n#### Installation\nThe officially supported method of installation for Julia is now using the `juliaup` version manager.\nThe [installer](https://github.com/JuliaLang/juliaup#windows) can be downloaded from the Windows store on Windows or run on MacOS or Linux with:\n\n```bash\ncurl -fsSL https://install.julialang.org | sh\n```\n#### Environments\nJulia comes with a standard environment and package manager named [`Pkg`](https://pkgdocs.julialang.org/v1/).\nInterestingly, the easiest way to use it is to run the Julia REPL (read-eval-print-loop), i.e. to run `julia` interactively.\nYou can do so by typing `julia` into the terminal.\nYou will then be presented with a terminal interface such as:\n```default\n   _       _ _(_)_     |  Documentation: https://docs.julialang.org\n  (_)     | (_) (_)    |\n   _ _   _| |_  __ _   |  Type \"?\" for help, \"]?\" for Pkg help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 1.8.0 (2022-08-17)\n _/ |\\__'_|_|_|\\__'_|  |  Official https://julialang.org/ release\n|__/                   |\n\njulia>\n```\nTyping `]` will put you into \"`Pkg` mode\":\n```default\n(@v1.8) pkg>\n```\nType `?` and hit enter to get options in this mode.\nWe can create and activate a new environment called workshop with the command:\n```default\n(@v1.8) pkg> activate --shared workshop\n```\nNote that the `--shared` flag will make a \"global\" environment that can be accessed from any directory.\nIf we were to leave out this flag, `Pkg` would put a `Project.toml` and `Manifest.toml` file in the current directory that contain the name of the environment, its installed packages, and their dependencies.\nThis can be useful to easily isolate and share environments.\nAfter running this command, our `Pkg` mode will have changed to represent the active environment:\n```default\n(@workshop) pkg>\n```\n\n#### Installing packages\nTo install some packages in the active environment, write:\n```default\n(@workshop) pkg> add Plots MLJ DataFrames Flux Pluto\n```\nThese packages will install and precompile.\nTo test one of them, press backspace to leave `Pkg` mode and input:\n```default\njulia> using Plots\n[ Info: Precompiling Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\njulia> x = range(0,10,100);\njulia> y = sin.(x);\njulia> plot(x,y)\n```\nThis should show a plot of a simple $\\sin$ curve.\nNote that the precompilation of `Plots` took some time.\nHowever, this will not need to occur again until the package is updated.\nAlso note that the call to `plot(x,y)` took some time.\nThis is due to the just-in-time compilation.\nNow that the compilation has been done for inputs of the types of `x` and `y`, if you run `plot(x,y)` again, it should be almost instantaneous.\n\n#### Cleaning up\nTo deactivate the environment, enter the `Pkg` mode again by pressing `]` on an empty line, then enter:\n\n```default\n(@workshop) pkg> activate\n```\nTo delete the environment we created you can delete the environment folder at the listed location at creation.\nThis is usually `/home/user/.julia/environments/workshop` on MacOS or Linux.\n\n#### References\n\n**Julia**\n\n- [Julia documentation](https://docs.julialang.org/en/v1/)\n- [Quick cheatsheet of Julia](https://juliadocs.github.io/Julia-Cheat-Sheet/)\n- [Comparison of the syntax of Julia, Python, and Matlab](https://cheatsheets.quantecon.org)\n\n**Packages**\n\nAs compared to Python, Julia has many scientific computing tools built into its standard library.\nThus, a lot of the functionality found in `numpy` are loaded by default.\nOn the other hand, because of the interoperability of the language and the reduced need for a polyglot codebase (i.e. needing C and Fortran code for a Python package to be fast), packages are usually much smaller modules in Julia.\nFor example, the functionality of the `scipy` package in Python can be found spread across possibly a dozen different packages in Julia.\nThis is convenient to only load and use what you need, but inconvenient in that it may require more searching to find and the interfaces may not be standardized.\nThe following are some packages that roughly recreate the essential Python packages [here](#python-resources-and-packages). \n\n- `numpy` - [Standard library](https://docs.julialang.org/en/v1/manual/arrays/),[`FFTW.jl`](https://juliamath.github.io/FFTW.jl/latest/)\n- `scipy` - [`Statistics.jl`]()\n- `matplotlib` - [`Plots.jl`](https://docs.juliaplots.org/latest/)\n- `scikit-learn` - [`MLJ.jl`](https://alan-turing-institute.github.io/MLJ.jl/dev/)\n- `pandas` - [`DataFrames.jl`](https://dataframes.juliadata.org/stable/)\n- `keras`,`tensorflow`,`pytorch` - [`Flux.jl`](https://fluxml.ai/Flux.jl/stable/)\n- `scikit-image` - [`Images.jl`](https://juliaimages.org/latest/install/)\n- `jupyter` - [`Pluto.jl`](https://github.com/fonsp/Pluto.jl) although you can use Julia with Jupyter via [`IJulia.jl`](https://julialang.github.io/IJulia.jl/stable/)\n\n",
    "supporting": [
      "workshop1_intro_files"
    ],
    "filters": [],
    "includes": {}
  }
}