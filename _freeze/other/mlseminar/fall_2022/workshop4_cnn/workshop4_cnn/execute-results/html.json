{
  "hash": "416c586f3976a3d168c422808ef6e8e5",
  "result": {
    "markdown": "---\nexecute:\n  daemon: 500\n  keep-ipynb: true\n---\n\n# Machine Learning Workshop -- Convolutional Neural Network (CNN)\n\n## Installing and loading some needed packages\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Needed package for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\n# Needed package for getting the current working directory\nimport os\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n# Needed package for builing the convolutional neural network\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\nfrom tensorflow.keras.utils import plot_model\n\n# Needed package for computer vision problems\nimport cv2\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2023-02-09 11:56:10.252324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-09 11:56:10.289686: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n```\n:::\n:::\n\n\n## Loading the MNIST data from keras library and split that into train and test dataset\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nimage_index = 0\nprint('The number for index = ' + str(image_index) + ' is ' + str(y_train[image_index])) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\r    8192/11490434 [..............................] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  532480/11490434 [>.............................] - ETA: 1s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 1064960/11490434 [=>............................] - ETA: 1s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 1982464/11490434 [====>.........................] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2572288/11490434 [=====>........................] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3375104/11490434 [=======>......................] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4014080/11490434 [=========>....................] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4751360/11490434 [===========>..................] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5046272/11490434 [============>.................] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 5980160/11490434 [==============>...............] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6529024/11490434 [================>.............] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6930432/11490434 [=================>............] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7569408/11490434 [==================>...........] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8060928/11490434 [====================>.........] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8568832/11490434 [=====================>........] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9043968/11490434 [======================>.......] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9388032/11490434 [=======================>......] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 9584640/11490434 [========================>.....] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10207232/11490434 [=========================>....] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10518528/11490434 [==========================>...] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11091968/11490434 [===========================>..] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11490434/11490434 [==============================] - 1s 0us/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe number for index = 0 is 5\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nplt.imshow(x_train[image_index], cmap='Greys')\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n<matplotlib.image.AxesImage at 0x7f2a285c43a0>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-4-output-2.png){width=415 height=411}\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nx_train.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n(60000, 28, 28)\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nx_train[image_index].shape\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n(28, 28)\n```\n:::\n:::\n\n\n## Normalize data and put them into the correct format\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\ninput_shape = (28, 28, 1)\n# Making sure that the values are float so that we can get decimal points after division\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint('Number of images in x_train', x_train.shape[0])\nprint('Number of images in x_test', x_test.shape[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx_train shape: (60000, 28, 28, 1)\nNumber of images in x_train 60000\nNumber of images in x_test 10000\n```\n:::\n:::\n\n\n## Convolutional Neural Network (CNN) structure\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten()) \nmodel.add(Dense(256, activation=tf.nn.relu))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation=tf.nn.softmax))\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nmodel.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n Layer (type)                Output Shape              Param #   \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d (Conv2D)             (None, 26, 26, 32)        320       \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n )                                                               \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n 2D)                                                             \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n flatten (Flatten)           (None, 800)               0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense (Dense)               (None, 256)               205056    \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dropout (Dropout)           (None, 256)               0         \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n dense_1 (Dense)             (None, 10)                2570      \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                                 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n=================================================================\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTotal params: 217,194\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTrainable params: 217,194\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNon-trainable params: 0\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n_________________________________________________________________\n```\n:::\n:::\n\n\n## Training the CNN\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.fit(x=x_train,y=y_train, epochs=5)\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nmodel.evaluate(x_test, y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r  1/313 [..............................] - ETA: 30s - loss: 0.0194 - accuracy: 1.0000\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/313 [===>..........................] - ETA: 0s - loss: 0.0453 - accuracy: 0.9874 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 82/313 [======>.......................] - ETA: 0s - loss: 0.0500 - accuracy: 0.9855\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r122/313 [==========>...................] - ETA: 0s - loss: 0.0600 - accuracy: 0.9836\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r163/313 [==============>...............] - ETA: 0s - loss: 0.0578 - accuracy: 0.9841\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r202/313 [==================>...........] - ETA: 0s - loss: 0.0492 - accuracy: 0.9862\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r241/313 [======================>.......] - ETA: 0s - loss: 0.0435 - accuracy: 0.9878\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r281/313 [=========================>....] - ETA: 0s - loss: 0.0386 - accuracy: 0.9890\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r313/313 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9891\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n[0.03790852800011635, 0.9890999794006348]\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nimage_index = 59\nplt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\npred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\nprint(' For image_index = ' + str(image_index) + ' CNN predicted number = ' + str(pred.argmax()))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r1/1 [==============================] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 50ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n For image_index = 59 CNN predicted number = 5\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-12-output-4.png){width=415 height=411}\n:::\n:::\n\n\n# In this part we are going to take a picture of your own handwriting and pass it into the CNN model, for doing that we need to do the following steps:\n\n## 1. Write a number in 6 different ways on a paper and transfer the picture into the same directory that your Jupyter Notebook is\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ncwd = os.getcwd()\nprint('current working directory is = ' + cwd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncurrent working directory is = /home/connor/GDrive/Software/cnrrobertson.github.io/other/mlseminar/fall_2022/workshop4_cnn\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfile = r'test_images/original_image.jpeg'\ntest_image_original = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n```\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nplt.imshow(test_image_original, cmap = 'gray')\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n<matplotlib.image.AxesImage at 0x7f29f938f880>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-15-output-2.png){width=580 height=392}\n:::\n:::\n\n\n## 2. Take a picture of each of them individually -- you can have only one picture and then crop it into 6 different pieces\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfig, axs = plt.subplots(2, 3)\n\n\ncounter = 1\nfor row_number in range(0, 2):\n    for col_number in range(0,3):\n        \n        file = r'test_images/copy_' + str(counter) +'.jpeg'\n        copy_image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n        axs[row_number, col_number].imshow(copy_image, cmap = 'gray')\n        counter = counter + 1\n\n```\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-16-output-1.png){width=569 height=416}\n:::\n:::\n\n\n## 4. Change the format of the picture into a readable form for your CNN model\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfile = r'test_images/copy_5.jpeg'\ncopy_1 = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\nplt.imshow(copy_1, cmap = 'gray')\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n<matplotlib.image.AxesImage at 0x7f29f84f2100>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-17-output-2.png){width=281 height=415}\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# copy_1_resized = cv2.resize(copy_1, (28, 28), interpolation = cv2.INTER_LINEAR)\ncopy_1_resized = cv2.resize(copy_1, (28, 28))\ncopy_1_resized = cv2.bitwise_not(copy_1_resized)\n\nplt.imshow(copy_1_resized, cmap = 'Greys')\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n<matplotlib.image.AxesImage at 0x7f29f8446580>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-18-output-2.png){width=415 height=411}\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\npred = model.predict(copy_1_resized.reshape(1, 28, 28, 1))\nprint('CNN predicted number = ' + str(pred.argmax()))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r1/1 [==============================] - ETA: 0s\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 37ms/step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCNN predicted number = 3\n```\n:::\n:::\n\n\n",
    "supporting": [
      "workshop4_cnn_files"
    ],
    "filters": [],
    "includes": {}
  }
}