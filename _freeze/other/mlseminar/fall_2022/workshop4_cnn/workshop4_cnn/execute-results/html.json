{
  "hash": "f208d50a4b3fb4f84a72f85cc0d5b3bd",
  "result": {
    "markdown": "---\nexecute:\n  daemon: 500\nformat:\n  html: default\n  ipynb: default\ntitle: Machine Learning Workshop -- Convolutional Neural Network (CNN)\n---\n\n\n\n\n\n## Installing and loading some needed packages\n\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# Needed package for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\n# Needed package for getting the current working directory\nimport os\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n# Needed package for builing the convolutional neural network\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\nfrom tensorflow.keras.utils import plot_model\n\n# Needed package for computer vision problems\nimport cv2\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n2023-05-30 15:18:20.540008: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-05-30 15:18:20.579240: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n```\n:::\n:::\n\n\n## Loading the MNIST data from keras library and split that into train and test dataset\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nimage_index = 0\nprint('The number for index = ' + str(image_index) + ' is ' + str(y_train[image_index])) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe number for index = 0 is 5\n```\n:::\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nplt.imshow(x_train[image_index], cmap='Greys')\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n<matplotlib.image.AxesImage at 0x7f92e15b2220>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-4-output-2.png){width=415 height=411}\n:::\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nx_train.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n(60000, 28, 28)\n```\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nx_train[image_index].shape\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n(28, 28)\n```\n:::\n:::\n\n\n## Normalize data and put them into the correct format\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\ninput_shape = (28, 28, 1)\n# Making sure that the values are float so that we can get decimal points after division\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\nx_train /= 255\nx_test /= 255\nprint('x_train shape:', x_train.shape)\nprint('Number of images in x_train', x_train.shape[0])\nprint('Number of images in x_test', x_test.shape[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nx_train shape: (60000, 28, 28, 1)\nNumber of images in x_train 60000\nNumber of images in x_test 10000\n```\n:::\n:::\n\n\n## Convolutional Neural Network (CNN) structure\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten()) \nmodel.add(Dense(256, activation=tf.nn.relu))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation=tf.nn.softmax))\n```\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nmodel.summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 26, 26, 32)        320       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 800)               0         \n                                                                 \n dense (Dense)               (None, 256)               205056    \n                                                                 \n dropout (Dropout)           (None, 256)               0         \n                                                                 \n dense_1 (Dense)             (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 217,194\nTrainable params: 217,194\nNon-trainable params: 0\n_________________________________________________________________\n```\n:::\n:::\n\n\n## Training the CNN\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy', \n              metrics=['accuracy'])\nmodel.fit(x=x_train,y=y_train, epochs=5)\n```\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nmodel.evaluate(x_test, y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r  1/313 [..............................] - ETA: 36s - loss: 0.1098 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 30/313 [=>............................] - ETA: 0s - loss: 0.0378 - accuracy: 0.9844 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/313 [=====>........................] - ETA: 0s - loss: 0.0503 - accuracy: 0.9834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 97/313 [========>.....................] - ETA: 0s - loss: 0.0576 - accuracy: 0.9836\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r129/313 [===========>..................] - ETA: 0s - loss: 0.0601 - accuracy: 0.9830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r162/313 [==============>...............] - ETA: 0s - loss: 0.0551 - accuracy: 0.9844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r194/313 [=================>............] - ETA: 0s - loss: 0.0509 - accuracy: 0.9855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r229/313 [====================>.........] - ETA: 0s - loss: 0.0459 - accuracy: 0.9869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r266/313 [========================>.....] - ETA: 0s - loss: 0.0413 - accuracy: 0.9878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r305/313 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9885\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r313/313 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9884\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n[0.03904067724943161, 0.9883999824523926]\n```\n:::\n:::\n\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nimage_index = 59\nplt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\npred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\nprint(' For image_index = ' + str(image_index) + ' CNN predicted number = ' + str(pred.argmax()))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 48ms/step\n For image_index = 59 CNN predicted number = 5\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-12-output-2.png){width=415 height=411}\n:::\n:::\n\n\n# In this part we are going to take a picture of your own handwriting and pass it into the CNN model, for doing that we need to do the following steps:\n\n## 1. Write a number in 6 different ways on a paper and transfer the picture into the same directory that your Jupyter Notebook is\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ncwd = os.getcwd()\nprint('current working directory is = ' + cwd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncurrent working directory is = /home/connor/GDrive/Software/cnrrobertson.github.io/other/mlseminar/fall_2022/workshop4_cnn\n```\n:::\n:::\n\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfile = r'test_images/original_image.jpeg'\ntest_image_original = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n```\n:::\n\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nplt.imshow(test_image_original, cmap = 'gray')\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n<matplotlib.image.AxesImage at 0x7f929e3b6fd0>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-15-output-2.png){width=580 height=392}\n:::\n:::\n\n\n## 2. Take a picture of each of them individually -- you can have only one picture and then crop it into 6 different pieces\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nfig, axs = plt.subplots(2, 3)\n\n\ncounter = 1\nfor row_number in range(0, 2):\n    for col_number in range(0,3):\n        \n        file = r'test_images/copy_' + str(counter) +'.jpeg'\n        copy_image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n        axs[row_number, col_number].imshow(copy_image, cmap = 'gray')\n        counter = counter + 1\n\n```\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-16-output-1.png){width=569 height=416}\n:::\n:::\n\n\n## 4. Change the format of the picture into a readable form for your CNN model\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfile = r'test_images/copy_5.jpeg'\ncopy_1 = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\nplt.imshow(copy_1, cmap = 'gray')\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n<matplotlib.image.AxesImage at 0x7f929d5d9e20>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-17-output-2.png){width=281 height=415}\n:::\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# copy_1_resized = cv2.resize(copy_1, (28, 28), interpolation = cv2.INTER_LINEAR)\ncopy_1_resized = cv2.resize(copy_1, (28, 28))\ncopy_1_resized = cv2.bitwise_not(copy_1_resized)\n\nplt.imshow(copy_1_resized, cmap = 'Greys')\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n<matplotlib.image.AxesImage at 0x7f929d53ef40>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](workshop4_cnn_files/figure-html/cell-18-output-2.png){width=415 height=411}\n:::\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\npred = model.predict(copy_1_resized.reshape(1, 28, 28, 1))\nprint('CNN predicted number = ' + str(pred.argmax()))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 35ms/step\nCNN predicted number = 8\n```\n:::\n:::\n\n\n",
    "supporting": [
      "workshop4_cnn_files"
    ],
    "filters": [],
    "includes": {}
  }
}