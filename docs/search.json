[
  {
    "objectID": "other/fun/fun.html",
    "href": "other/fun/fun.html",
    "title": "Just for Fun",
    "section": "",
    "text": "This is a collection of code doodles (almost literally since most produce nice plots or videos)."
  },
  {
    "objectID": "other/fun/fun.html#doodles",
    "href": "other/fun/fun.html#doodles",
    "title": "Just for Fun",
    "section": "Doodles",
    "text": "Doodles\n\nExternal angles of a polygon sum to \\(2\\pi\\)\nVisually comparing the complexity of the heliocentric and geocentric models of the solar system"
  },
  {
    "objectID": "other/fun/heliocentric_geocentric.html",
    "href": "other/fun/heliocentric_geocentric.html",
    "title": "Heliocentrism vs Geocentrism",
    "section": "",
    "text": "Another fun little animation that I saw recently was the difference in the dynamics of the solar system when approaching the equations from a heliocentric (sun-centered) or geocentric (Earth-centered) perspective. Although it’s clear now that we orbit the sun and a sun-centered model of the solar system is more correct, it wasn’t always obvious. This concept extends to systems that we have not yet nailed down completely. This simple animation demonstrates that identifying the correct perspective when modeling a system can have a huge pay off in the simplicity of your result.\nI thought I’d try to recreate this little animation with Makie.jl as I did previously with the polygon GIF."
  },
  {
    "objectID": "other/fun/heliocentric_geocentric.html#setting-up",
    "href": "other/fun/heliocentric_geocentric.html#setting-up",
    "title": "Heliocentrism vs Geocentrism",
    "section": "Setting up",
    "text": "Setting up\nIn this animation, we’ll be rotating some circular shapes around the point representing either the sun or the Earth and tracing their paths as they progress. First, let’s plot the initial frame of the animation using a Figure with 2 axes:\n\nusing Pkg;\nPkg.activate(\".\");\nusing CairoMakie;\n\n\nf = Figure(resolution=(800,400));\naxes = [Axis(f[1,1]);Axis(f[1,2])]\nfor ax in axes ax.limits=(-22,22,-22,22) end\nfunction remove_axis_decor!(ax)\n  ax.topspinevisible = false; ax.bottomspinevisible = false\n  ax.leftspinevisible = false; ax.rightspinevisible = false\n  ax.xgridvisible = false; ax.ygridvisible = false\n  ax.xticksvisible = false; ax.yticksvisible = false\n  ax.xticklabelsvisible = false; ax.yticklabelsvisible = false\nend\nremove_axis_decor!.(axes)\n\nWe can now layout the different planets via a simple scatter plot in each axis. Of course, we cannot use the correct proportions or distances or the plot would be hard to understand. Instead, I’ll settle for simple size differences between the planets and the sun and a somewhat uniform distance between each.\n\nnum_bodies = 9\nbody_locs1 = [(float(i),0.0) for i in 0:2:2(num_bodies-1)]\nbody_locs2 = [(float(i),0.0) for i in -6:2:2(num_bodies-1)-6]\nbody_sizes = 3 .* [9,3,3,4,2,5,6,4,4]\nbody_colors = [:yellow,:red,:red,:blue,:red,:red,:red,:red,:red]\ns1 = scatter!(axes[1], body_locs1, markersize=body_sizes, color=body_colors)\ns2 = scatter!(axes[2], body_locs2, markersize=body_sizes, color=body_colors)\ndisplay(f)"
  },
  {
    "objectID": "other/fun/heliocentric_geocentric.html#animation",
    "href": "other/fun/heliocentric_geocentric.html#animation",
    "title": "Heliocentrism vs Geocentrism",
    "section": "Animation",
    "text": "Animation\nOkay! Easy as that. Now, we can move on to animating the rotation of the bodies. Each planet will rotate at a different speed and will go until again lining up as they started.\n\nbody_speeds = [0.0,47.87,35.02,29.78,24.077,13.07,9.69,6.81,5.43] ./ 200\nsun_speed2 = body_speeds[4]\norbit_radii1 = [bl[1] for bl in body_locs1]\norbit_radii2 = [bl[1] for bl in body_locs2]\n\n# Use Observable to add time dependence to planet locations\ntime_i = Observable(0.0)\nbody_xs1 = @lift(orbit_radii1 .* cos.(-1 .* body_speeds .* $time_i))\nbody_ys1 = @lift(orbit_radii1 .* sin.(-1 .* body_speeds .* $time_i))\nbody_xs2 = @lift(vcat(\n    orbit_radii2[1]*cos(-sun_speed2*$time_i),\n    orbit_radii2[1]*cos(-sun_speed2*$time_i) + orbit_radii1[2]*cos(-body_speeds[2]*$time_i),\n    orbit_radii2[1]*cos(-sun_speed2*$time_i) + orbit_radii1[3]*cos(-body_speeds[3]*$time_i),\n    0.0,\n    orbit_radii2[1]*cos(-sun_speed2*$time_i) .+ orbit_radii1[5:end] .* cos.(-1 .* body_speeds[5:end] .* $time_i)\n))\nbody_ys2 = @lift(vcat(\n    orbit_radii2[1]*sin(-sun_speed2*$time_i),\n    orbit_radii2[1]*sin(-sun_speed2*$time_i) + orbit_radii1[2]*sin(-body_speeds[2]*$time_i),\n    orbit_radii2[1]*sin(-sun_speed2*$time_i) + orbit_radii1[3]*sin(-body_speeds[3]*$time_i),\n    0.0,\n    orbit_radii2[1]*sin(-sun_speed2*$time_i) .+ orbit_radii1[5:end] .* sin.(-1 .* body_speeds[5:end] .* $time_i)\n))\n\nempty!(axes[1].scene.plots)\nempty!(axes[2].scene.plots)\ns1 = scatter!(axes[1], body_xs1, body_ys1, markersize=body_sizes, color=body_colors)\ns2 = scatter!(axes[2], body_xs2, body_ys2, markersize=body_sizes, color=body_colors)\n\n# Create GIF by iterating time\nsteps = 300\nrecord(f, \"gifs/heliocentric_geocentric1.gif\", 1:steps) do t\n    time_i[] = t\nend\n\n\nNice! We’ve got the two animations moving well. Note that since the animation was fairly straightforward and only required updating the scatter plot locations, we were able to use an Observable for time in Makie. This object allows us to create the initial scatter plots where the scatter locations are wrapped with the @lift macro with the interpolating $time_i. Now, when our Observable, time_i is updated, the scatter points and subsequently the scatter plots are updated. Using this nifty tool, our recording loop is very straightforward. However, using the @lift macro is not particularly intuitive and it took some trial and error to get the definition of the scatter points correctly wrapped in an Observable. Hence, the definitions of body_xs2 and body_ys2 are so messy..\nOur next step is to add the path tracing of the planets to each plot. Again, this is a fairly simple procedure that could be completed with an Observable.\n\n# Line observables\nline_locs1 = [Observable([body_locs1[i]]) for i in 1:num_bodies]\nline_locs2 = [Observable([body_locs2[i]]) for i in 1:num_bodies]\n\nempty!(axes[1].scene.plots)\nempty!(axes[2].scene.plots)\nfor i in 1:num_bodies\n    lines!(axes[1], line_locs1[i], color=body_colors[i])\n    lines!(axes[2], line_locs2[i], color=body_colors[i])\nend\ns1 = scatter!(axes[1], body_xs1, body_ys1, markersize=body_sizes, color=body_colors)\ns2 = scatter!(axes[2], body_xs2, body_ys2, markersize=body_sizes, color=body_colors)\n\n# Create GIF by iterating time\nsteps = 300\nrecord(f, \"gifs/heliocentric_geocentric.gif\", 1:steps) do t\n    time_i[] = t\n    for i in 1:num_bodies\n        line_locs1[i][] = push!(line_locs1[i][], (body_xs1[][i], body_ys1[][i]))\n        line_locs2[i][] = push!(line_locs2[i][], (body_xs2[][i], body_ys2[][i]))\n    end\nend\n\n\nAlright! Our animation is now complete."
  },
  {
    "objectID": "other/fun/polygon_angles.html",
    "href": "other/fun/polygon_angles.html",
    "title": "The exterior angles of a polygon make a circle",
    "section": "",
    "text": "I recently saw a fun little GIF from a weekly news email I get called the New Paper. It shows a simple plot of the exterior angles of a few polygons. As the polygons shrink, the exterior angles combine to eventually make a circle, which shows a simple graphical example of how the exterior angles of any polygon add to \\(2\\pi\\). \n\nI thought I’d try to recreate this little GIF with my favorite plotting library Makie.jl."
  },
  {
    "objectID": "other/fun/polygon_angles.html#setting-up",
    "href": "other/fun/polygon_angles.html#setting-up",
    "title": "The exterior angles of a polygon make a circle",
    "section": "Setting up",
    "text": "Setting up\nBasically, we can start by getting the plots of each polygon set. We can then animate the sides of the polygons shrinking.\nTo start we are going to need a Figure with 4 axes:\n\nusing Pkg;\nPkg.activate(\".\");\nusing CairoMakie;\n\n\nf = Figure(resolution=(800,800));\naxes = [\n  Axis(f[1,1]) Axis(f[1,2]);\n  Axis(f[2,1]) Axis(f[2,2])\n]\nfor ax in axes ax.limits=(-6,6,-6,6) end\n\nWe can now list the vertices for each polygon:\n\npoly11 = [(-2.0,3.0),(3.0,-3.0),(-4.0,-2.0),(-2.0,3.0)];\npoly12 = [(-3.0,2.0),(1.0,1.0),(3.0,-2.0),(-4.0,-1.0),(-3.0,2.0)];\npoly21 = [(-1.0,3.0),(1.0,3.0),(3.0,-1.0),(1.0,-3.0),(-2.0,-2.0),(-3.0,1.0),(-1.0,3.0)];\npoly22 = [(-1.0,2.0),(1.0,2.0),(4.0,-1.0),(2.0,-3.0),(-4.0,-1.0),(-1.0,2.0)];\n\nwhere poly11 is the polygon in the 1st row and 1st column. Plotting these lines on each respective axis, we get:\n\nlines!(axes[1,1],poly11,color=:black);\nlines!(axes[1,2],poly12,color=:black);\nlines!(axes[2,1],poly21,color=:black);\nlines!(axes[2,2],poly22,color=:black);\npoly!(axes[1,1],poly11,transparency=true,color=RGBAf(1.0,0.6,0.0,0.2));\npoly!(axes[1,2],poly12,transparency=true,color=RGBAf(0.0,0.0,1.0,0.2));\npoly!(axes[2,1],poly21,transparency=true,color=RGBAf(0.5,0.0,0.5,0.2));\npoly!(axes[2,2],poly22,transparency=true,color=RGBAf(0.0,0.5,0.0,0.2));\ndisplay(f)\n\n\n\n\nThese are obviously not exactly the polygons in the GIF, but they are generally similar and use nice easy vertex coordinates. Now, in order to accentuate the exterior angles, the GIF uses lines which extend beyond the vertices. To achieve this, we can consider each line segment and shift the first vertex some distance in the opposite direction of the second vertex. To do so, we should shift adjust our polygon representation to separate each line segment:\n\nlpoly11 = [[poly11[i],poly11[i+1]] for i in 1:length(poly11)-1];\nlpoly12 = [[poly12[i],poly12[i+1]] for i in 1:length(poly12)-1];\nlpoly21 = [[poly21[i],poly21[i+1]] for i in 1:length(poly21)-1];\nlpoly22 = [[poly22[i],poly22[i+1]] for i in 1:length(poly22)-1];\ndisplay(lpoly11)\n\n3-element Vector{Vector{Tuple{Float64, Float64}}}:\n [(-2.0, 3.0), (3.0, -3.0)]\n [(3.0, -3.0), (-4.0, -2.0)]\n [(-4.0, -2.0), (-2.0, 3.0)]\n\n\nWe can now the vector between the first and second indices of each line segment and shift our first vertex by the negative of that vector. That is a mouthful but more easily written mathematically. If we consider a single line segment with vertices \\(v_1\\) and \\(v_2\\), we can calculate the distance between them \\(d = v_2 - v_1\\) such that \\(v_1 + d = v_2\\) and then redefine our first vertex in the opposite direction as \\(v_1^* = v_1 - l\\frac{d}{\\|d\\|}\\) where \\(l\\) is the length of the external line. This boils down to the following:\n\nfunction shift_first_vertices!(lpoly, l=2)\n   for line in lpoly\n     v1 = collect(line[1]); v2 = collect(line[2])\n     d = v2 - v1\n     v1star = v1 - l*d/sqrt(d[1]^2+d[2]^2)\n     line[1] = tuple(v1star...)\n   end\nend\nshift_first_vertices!(lpoly11)\nshift_first_vertices!(lpoly12)\nshift_first_vertices!(lpoly21)\nshift_first_vertices!(lpoly22)\nfunction plot_line_segments!(ax,lpoly)\n  lines = []\n  for line in lpoly push!(lines,lines!(ax,line,color=:black)) end\n  return lines\nend\nplot_line_segments!(axes[1,1],lpoly11)\nplot_line_segments!(axes[1,2],lpoly12)\nplot_line_segments!(axes[2,1],lpoly21)\nplot_line_segments!(axes[2,2],lpoly22)\ndisplay(f)\n\n\n\n\nOnce we have these lines in place, we can add the external angles. Ironically, the best tool in Makie for these angle drawings is the poly! function which plots a filled polygon from some given vertices. Thus, we need to compute the vertices of the arc for each angle of each polygon.\nThis computation can be done by taking two connected line segments \\(d_1\\) and \\(d_2\\), identifying the angle between them using the law of cosines \\(\\arccos(d_1 \\cdot d_2)\\), and sampling points along the arc of given radius \\(l\\). Sampling the arc requires a little change of coordinates to center the points around the vertex connecting the two line segments and to rotate the standard \\(x\\) and \\(y\\) coordinates to align \\(x\\) with \\(d_1\\) and \\(y\\) with \\(d_1^\\perp\\). This is, in my opinion, the most challenging part of the plot.\n\nfunction angle_vertices(line1,line2,l=1)\n  v1 = collect(line1[1])\n  v2 = collect(line1[2]) # Shared vertex\n  v3 = collect(line2[2])\n  d1 = v2-v1\n  d2 = v3-v2\n  # Line segment directions (normalized\n  d1 ./= sqrt(d1[1]^2+d1[2]^2)\n  d2 ./= sqrt(d2[1]^2+d2[2]^2)\n  d1perp = [d1[2],-d1[1]]\n  vertex = tuple(v2...)\n  # Computing angle between lines, then sampling arc points\n  angle = acos(d1'*d2)\n  angle = isnan(angle) ? 0.0 : angle\n  angles = range(0, angle, length=10)\n  # arc has radius l, origin at v2, \"x\"-direction is d1, \"y\"-direction is d1perp\n  arc_points = [tuple(@.( v2 - l*(d1*cos(a) + d1perp*sin(a)))...) for a in angles]\n  vertices = vcat(vertex,arc_points,vertex)\n  return vertices\nend\nfunction plot_arcs!(ax,lpoly)\n  arcs = []\n  colors = to_colormap(:seaborn_colorblind)\n  for i in 1:length(lpoly)\n    if i+1 > length(lpoly) # The angle between the last line segment and first\n      color = colors[i+1]\n      arc_vertices = angle_vertices(lpoly[i],lpoly[1])\n    else\n      color = colors[i]\n      arc_vertices = angle_vertices(lpoly[i],lpoly[i+1])\n    end\n    push!(arcs,poly!(ax,arc_vertices,color=color))\n  end\n  return arcs\nend\nplot_arcs!(axes[1,1],lpoly11)\nplot_arcs!(axes[1,2],lpoly12)\nplot_arcs!(axes[2,1],lpoly21)\nplot_arcs!(axes[2,2],lpoly22)\ndisplay(f)\n\n\n\n\nNow, removing the axes decorations, we have a clean plot of (almost) the first frame of the GIF:\n\nfunction remove_axis_decor!(ax)\n  ax.topspinevisible = false; ax.bottomspinevisible = false\n  ax.leftspinevisible = false; ax.rightspinevisible = false\n  ax.xgridvisible = false; ax.ygridvisible = false\n  ax.xticksvisible = false; ax.yticksvisible = false\n  ax.xticklabelsvisible = false; ax.yticklabelsvisible = false\nend\nremove_axis_decor!.(axes)\ndisplay(f)"
  },
  {
    "objectID": "other/fun/polygon_angles.html#animating",
    "href": "other/fun/polygon_angles.html#animating",
    "title": "The exterior angles of a polygon make a circle",
    "section": "Animating",
    "text": "Animating\nWith the initial plot now done, to complete the animation, it remains to shrink each polygon until the angles come together to form a circle. This can be simply done (with slight error) by computing the center of each polygon via averaging, centering the vertices around that center, then shrinking the vertices proportional to the number of steps in the animation. Putting everything together:\n\n# Initialize\nf = Figure(resolution=(800,800));\naxes = [\n  Axis(f[1,1]) Axis(f[1,2]);\n  Axis(f[2,1]) Axis(f[2,2])\n]\nfor ax in axes ax.limits = (-6,6,-6,6) end\nremove_axis_decor!.(axes)\npoly11 = [(-2.0,3.0),(3.0,-3.0),(-4.0,-2.0),(-2.0,3.0)];\npoly12 = [(-3.0,2.0),(1.0,1.0),(3.0,-2.0),(-4.0,-1.0),(-3.0,2.0)];\npoly21 = [(-1.0,3.0),(1.0,3.0),(3.0,-1.0),(1.0,-3.0),(-2.0,-2.0),(-3.0,1.0),(-1.0,3.0)];\npoly22 = [(-1.0,2.0),(1.0,2.0),(4.0,-1.0),(2.0,-3.0),(-4.0,-1.0),(-1.0,2.0)];\n# Polygon average centers\nfunction compute_center(poly)\n  vec(sum(hcat(collect.(poly)...),dims=2)./length(poly))\nend\nc11 = compute_center(poly11)\nc12 = compute_center(poly12)\nc21 = compute_center(poly21)\nc22 = compute_center(poly22)\nfunction shrink_polygon(poly,c,step,steps)\n  new_vertices = similar(poly)\n  for i in eachindex(poly)\n    vertex = collect(poly[i]) - c\n    new_vertex = @. vertex*((steps-step)/(steps))\n    new_vertices[i] = tuple((new_vertex + c)...)\n  end\n  return new_vertices\nend\n\n# Animation (somewhat inefficient since it doesn't use Observables)\nsteps = 120\nrecord(f, \"gifs/angle_gif.gif\", vcat(1:(steps-1),fill(steps-1,steps÷4),(steps-1):-1:1)) do t\n  empty!(axes[1,1].scene.plots)\n  empty!(axes[1,2].scene.plots)\n  empty!(axes[2,1].scene.plots)\n  empty!(axes[2,2].scene.plots)\n  npoly11 = shrink_polygon(poly11,c11,t,steps)\n  npoly12 = shrink_polygon(poly12,c12,t,steps)\n  npoly21 = shrink_polygon(poly21,c21,t,steps)\n  npoly22 = shrink_polygon(poly22,c22,t,steps)\n  lpoly11 = [[npoly11[i],npoly11[i+1]] for i in 1:length(npoly11)-1];\n  lpoly12 = [[npoly12[i],npoly12[i+1]] for i in 1:length(npoly12)-1];\n  lpoly21 = [[npoly21[i],npoly21[i+1]] for i in 1:length(npoly21)-1];\n  lpoly22 = [[npoly22[i],npoly22[i+1]] for i in 1:length(npoly22)-1];\n  shift_first_vertices!(lpoly11)\n  shift_first_vertices!(lpoly12)\n  shift_first_vertices!(lpoly21)\n  shift_first_vertices!(lpoly22)\n  poly!(axes[1,1],npoly11,transparency=true,color=RGBAf(1.0,0.6,0.0,0.2));\n  poly!(axes[1,2],npoly12,transparency=true,color=RGBAf(0.0,0.0,1.0,0.2));\n  poly!(axes[2,1],npoly21,transparency=true,color=RGBAf(0.5,0.0,0.5,0.2));\n  poly!(axes[2,2],npoly22,transparency=true,color=RGBAf(0.0,0.5,0.0,0.2));\n  plot_arcs!(axes[1,1],lpoly11)\n  plot_arcs!(axes[1,2],lpoly12)\n  plot_arcs!(axes[2,1],lpoly21)\n  plot_arcs!(axes[2,2],lpoly22)\n  plot_line_segments!(axes[1,1],lpoly11)\n  plot_line_segments!(axes[1,2],lpoly12)\n  plot_line_segments!(axes[2,1],lpoly21)\n  plot_line_segments!(axes[2,2],lpoly22)\nend"
  },
  {
    "objectID": "other/other.html",
    "href": "other/other.html",
    "title": "Other",
    "section": "",
    "text": "This section is made up of various other resources related to my interests or activities. Some are for specific events like the Machine Learning and Optimization seminar at NJIT, some might be useful for other people, and some are just for fun."
  },
  {
    "objectID": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html",
    "href": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html",
    "title": "Workshop 1: Python set up, machine learning basics, gradient descent, and automatic differentiation",
    "section": "",
    "text": "Other formats\n\n\n\n\n\nDownload the workshop as a Jupyter notebook here.\nAfter downloading the workshop Jupyter notebook, you can upload it to Google Colab to get a quick start, but you will not be able to see the animations."
  },
  {
    "objectID": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#overview",
    "href": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#overview",
    "title": "Workshop 1: Python set up, machine learning basics, gradient descent, and automatic differentiation",
    "section": "Overview",
    "text": "Overview\n\nMachine Learning and Optimization Seminar\nThe goal of the Machine Learning and Optimization seminar this year is to expose the participants to topics in machine learning and optimization by:\n\nFacilitating hands-on workshops and group discussions to explore and gain experience\nInviting speakers to introduce machine learning and optimization concepts\n\nWe are excited to get started on this but recognize that since neither machine learning nor optimization are standardized in the department, participants will have a varied level of exposure to different topics. Our hope is that we can use this disparity of experience to increase collaboration during the workshops in a way that can’t be achieved during the talks. All are encouraged to share their knowledge and experience with one another openly during the workshops and to give feedback to the organizers after.\nAll workshop material will be available here for later reference.\nThis first workshop is focused on tooling and the basic concepts of machine learning and optimization with the goal that everyone can be on the same footing for later workshops."
  },
  {
    "objectID": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#your-python-environment",
    "href": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#your-python-environment",
    "title": "Workshop 1: Python set up, machine learning basics, gradient descent, and automatic differentiation",
    "section": "Your Python environment",
    "text": "Your Python environment\nIt is safe to say that Python is the language of choice for machine learning. This interpreted language has a very clear and high-level syntax, is extremely convenient for interactive programming and debugging, and has an enormous user base of enterprises, researchers, and hobbyists who have built an almost infinite collection of open-source packages for every topic. For these three reasons the workshops for this seminar will use Python.\nTo get started, we will give the basics of the Python programming language. Just kidding! That would take too long. We will instead guide you on how to install Python most conveniently, teach you how to get started learning about Python, and then point you to a curated library of much more high-quality instruction for using Python. A list of some such references as well as documentation for setup and important Python packages can be found in the Appendix here.\n\nSetting up\n\n\n\n\n\n\nTip\n\n\n\nIf you are looking for the easiest and most immediate way to get going with a Python Jupyter Notebook, check out the Google Colab section.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis section will require use of a terminal emulator for installing and running Python. If you are not familiar with the terminal, check out this quick tutorial to get started.\nIf you are using a computer with Windows, the terminal instructions may not apply.\n\n\nPython is installed by default on MacOS and most Linux distributions. However, it can be challenging to navigate between the versions and packages that your operating system uses and those needed for other projects. Thus, there are a variety of version, package, and environment management tools:\n\nVersion management: Which version of Python are you using? Can you change versions to run a specific Python program if it requires?\n\npyenv\nconda/mamba\n\nPackage management: How can you install the many amazing Python packages people have created?\n\npip\nconda/mamba\n\nEnvironment management: If you have two projects that require different packages (or different versions of the same package), can you switch which packages are available depending on which project you are working on?\n\nvenv\nvirtualenv\npoetry\nconda/mamba\nmany more\n\n\nThe conda package manager is the only one that fills all three roles. It is formally a part of the Anaconda Python distribution which is a favorite in the fields of data science and machine learning. mamba is a newer and faster rewrite used in exactly the same way and which is highly recommended.\nThe best way to get started with mamba is to install mambaforge. You can find installer downloads for Windows, MacOS, or Linux here.\nFor Windows, run the .exe file once it is downloaded.\nFor MacOS and Linux, open a terminal and navigate to the download location:\ncd ~/Downloads\nThen run the installer as follows:\n./Mambaforge-Linux-x86_64.sh\nThe installer will walk you through a few steps and end by asking if you’d like to “initialize Mambaforge by running conda init?” Answer yes and restart your terminal. This final command will have added conda and mamba to your system $PATH variable, which means it is available to your terminal. Once restarted, run mamba -V to print the version and to verify that the installation worked.\n\n\nEnvironments\nThe idea of a conda/mamba environment is that once an environment is created and activated, all new packages installed will be added to that environment and will be accessible to any Python program run while the environment is active. As an example, let’s create an environment called workshop with a specific version of Python installed. The following will create the environment and install a specific version of python:\nmamba create -n workshop python=3.9\nOnce created, we can list our environments via the command\nmamba env list\n# conda environments:\n#\nbase                     /home/user/mambaforge\nworkshop                 /home/user/mambaforge/envs/workshop\nNote that there is a “base” environment which is where conda and mamba themselves are installed as well as their dependencies. The best practice is to create an environment for each of your projects to minimize dependency issues (when packages require separate versions of the same package).\nTo activate our new environment:\nmamba activate workshop\nRunning mamba env list will now show our active environment via an asterisk:\nbase                     /home/user/mambaforge\nworkshop              *  /home/user/mambaforge/envs/workshop\n\n\nInstalling packages\nNow that we have activated the workshop conda environment, let’s install some common machine learning packages in Python. It is as easy as writing:\nmamba install numpy matplotlib pandas jupyter scipy scikit-learn scikit-image\nThis command will search the conda-forge repository of packages and install the most up-to-date versions (the forge in mambaforge).\n\n\n\n\n\n\nTip\n\n\n\nEither conda or mamba could be used for all the commands discussed in this section. However, mamba is significantly faster when installing packages.\n\n\nNow that these packages have been installed, we can easily use them in an interactive ipython prompt (installed with the jupyter package):\nipython\nPython 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50)\nType 'copyright', 'credits' or 'license' for more information\nIPython 8.4.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: import numpy as np\n\nIn [2]: import matplotlib.pyplot as plt\n\nIn [3]: x = np.linspace(0,10,100)\n\nIn [4]: y = np.sin(x)\n\nIn [5]: plt.plot(x,y); plt.show()\nThis should plot a simple \\(\\sin\\) curve.\n\n\nCleaning up\nAfter we are done using the environment that has our desired version of Python and the needed packages, we can go back to our regular terminal by deactivating the environment:\nmamba deactivate workshop\nIf we have somehow broken our environment and need to remove it:\nmamba env remove -n workshop\nThere are many more commands and functionalities that conda and mamba provide that can be found in the python resources and packages section of the Appendix.\n\n\nGoogle Colab\nAs an alternative to the entire procedure above, you can use an online Jupyter Notebook service hosted by Google called Colab. This service will get you up and running immediately but cannot save your environment between notebooks and has limited functionality to run scripts, save data, view animations, change package versions, etc. Thus, if your notebook requires a package that is not installed by default, you will need to add the installation command in one of the first notebook cells. For example, to install the reservoirpy package, we would write in a notebook cell:\n!pip install reservoirpy\nIn a notebook, the ! denotes a terminal command. The package will now be ready for import and use within the current notebook session:\nfrom reservoirpy.nodes import Input,Reservoir,Ridge"
  },
  {
    "objectID": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#basic-concepts-of-machine-learning",
    "href": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#basic-concepts-of-machine-learning",
    "title": "Workshop 1: Python set up, machine learning basics, gradient descent, and automatic differentiation",
    "section": "Basic concepts of machine learning",
    "text": "Basic concepts of machine learning\nMachine learning is, at its most basic, automated data analysis, usually with the goal of finding patterns or making predictions. The “machines” in this analysis are equations or algorithms and the “learning” is usually some form of parameter selection and/or fitting. Due to the uncertain nature of most data, the majority of these models are probabilistic in nature. In fact, it can be hard to distinguish the methodological lines between what is termed “machine learning” and the field of statistics. However, there are a few important distinctions between the tools, goals, and terminology of the two areas. Today, machine learning has emerged as a broad description of almost any data-driven computing which may or may not include classical descriptive and inferential statistics [1].\nAt first glance, machine learning can be separated into three main classes:\n\nSupervised learning: Given dependent and independent variable data, train a model which effectively maps the independent variable data to produce the dependent variable data.\n\nGeneralized linear models (linear, logistic, etc. regression)\nNaive Bayes\nNeural networks (most)\nSupport vector machine (SVM)\nRandom forests\netc.\n\nUnsupervised learning: Given data, find patterns (no specified output, though there is still a measure of success)\n\nClustering\nMixture models\nDimensionality reduction\nAssociation rules\netc.\n\nReinforcement learning: Given input data and desired outcomes, simulate and use the results to update a model to improve the simulation’s ability to achieve those outcomes\n\nQ-learning\nSARSA\netc.\n\n\nThere is an enormous amount of current interest in machine learning methods and there is a corresponding amount of high-quality material discussing it. We will end the introduction here and direct you to established textbooks [1–3], NJIT classes (Math 478, Math 678, Math 680, CS 675, CS 677), and online resources (too many to even start listing).\n\nGeneral procedure\nIn practice, machine learning algorithms often boil down to an optimization problem. To characterize this in a few steps, consider a problem with data \\(x\\):\n\nSelect a model representation \\(f\\) with parameters \\(p\\) for the problem: \\[\ny = f(x;p)\n\\]\nDetermine an appropriate objective function \\(\\mathcal{L}\\): \\[\n\\mathcal{L}(f(x;p),x)\n\\]\nUse an optimization method \\(\\mathcal{O}\\) with parameters \\(d\\) to find parameters \\(p\\) that minimize or maximize the objective for the model: \\[\np^* = \\mathcal{O}(\\mathcal{L},f,x;d)\n\\]\n\nIn some sense, this is the same procedure used for inverse problems in traditional applied mathematics but with a broader set of models \\(f\\) that may or may not be based on first-principles understanding of the problem.\n\n\nIncorporating data\nDepending on the class of problem considered (supervised, unsupervised, or reinforcement), there are a variety of choices for models \\(f\\) and objectives \\(\\mathcal{L}\\). For supervised learning (the most common), the objective is often to predict or generate the output or dependent variable data of some process. For this, data can be separated into three sets:\n\nTraining data (\\(x\\)): used to tune the parameters \\(p\\)\nValidation data (\\(x^v\\)): used to evaluate the generalization of the model \\(f\\) to data not in the training set during training\nTesting data (\\(x^t\\)): used to benchmark the predictive or generative ability of the model after training is completed"
  },
  {
    "objectID": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#a-first-machine-learning-problem",
    "href": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#a-first-machine-learning-problem",
    "title": "Workshop 1: Python set up, machine learning basics, gradient descent, and automatic differentiation",
    "section": "A first machine learning problem",
    "text": "A first machine learning problem\n\n\n\n\n\n\nNote\n\n\n\nThe code for this problem will require the following packages: numpy, matplotlib, autograd\n\n\nThese workshops are about learning by doing, so let’s build understanding by fitting a simple “machine” to some data as a supervised problem. Consider some data \\((x,y)\\):    \n\n\nData generation\nimport numpy as np\nimport matplotlib.pyplot as plt\n# To see animations in a Jupyter notebook, uncomment the following line:\n# %matplotlib notebook\ndef f_known(x):\n    part1 = np.exp(-x)*(np.sin((x)**3) + np.sin((x)**2) - x)\n    part2 = 1/(1 + np.exp(-1*(x-1)))\n    return part1 + part2\nxsamples = np.random.uniform(-1/2,5,100)\nysamples = f_known(xsamples)\nplt.scatter(xsamples,ysamples)\nplt.xlabel(\"$x$\"); plt.ylabel(\"$y$\"); plt.title(\"Data\")\nplt.show()\n\n\n\n\n\nWe would like to fit a model of the following form to this data: \\[\nf(x;p_0,p_1) = e^{-p_0x}(\\sin((p_0x)^3) + \\sin((p_0x)^2) - p_0x) + \\frac{1}{1 + e^{-p_1(x-1)}}\n\\] \nTo formulate this as a machine learning/optimization problem, we can consider an objective/loss to minimize the \\(L^2\\) norm distance between the model output \\(f(x)\\) and the true data \\(y\\): \\[\n\\mathcal{L(f(x;\\vec{p}),y)} = ||f(x) - y||_2^2\n\\] The problem can then be written as the unconstrained optimization problem: \\[\np^* = \\underset{\\vec{p}}{\\text{minimize }} \\mathcal{L}(f(x;\\vec{p}),y)\n\\] We then expect our model \\(f(x;p^*)\\) to represent a “machine” that has accurately “learned” the relationship between \\(x\\) and \\(y\\).\nThere are several ways to approach this problem, but a simple and popular approach for a continuous and unconstrained problem is to use an iterative gradient method.\n\nGradient descent\nGradient descent is a straightforward method taught early in an undergraduate numerical methods class. Its simplicity and relatively low computational cost has made it popular for machine learning methods (which can contain enough parameters that second-order methods, like Newton’s method, are infeasibly expensive because of the Hessian computation). Beginning with an initial parameter guess \\(\\vec{p}_0\\), its update procedure can be written as: \\[\n\\begin{align*}\n\\vec{p}^{i+1} &= \\vec{p}^i + v^i \\\\\nv^i &= -\\alpha \\nabla_p \\mathcal{L}\n\\end{align*}\n\\] where \\(\\alpha\\) controls the step size in the direction of the gradient (usually called a “learning rate” in machine learning). This method will follow the gradient of the objective/loss \\(\\mathcal{L}\\) until the objective is sufficiently small, or until it reaches a steady state.\nSimply implemented in Python, this method can be written as:\n\ndef gradient_descent(f_p,x0,alpha=.2,tol=1e-12,steps=1000):\n    x = x0\n    xs = [x]\n    for s in range(steps):\n        v_i = -alpha*f_p(x)\n        xnew = x + v_i\n        if np.linalg.norm(f_p(xnew)) < tol:\n            print(\"Converged to objective loss gradient below {} in {} steps.\".format(tol,s))\n            return x,xs\n        elif np.linalg.norm(xnew - x) < tol:\n            print(\"Converged to steady state of tolerance {} in {} steps.\".format(tol,s))\n            return x,xs\n        x = xnew\n        xs.append(x)\n    print(\"Did not converge after {} steps (tolerance {}).\".format(steps,tol))\n    return x,xs\n\nHowever, this method contains a troublesome parameter \\(\\alpha\\) which, if chosen too large, could prevent convergence of the solution or, if chosen too small, could require an unreasonable number of steps to converge. The method itself is also prone to terminate in local minima rather than in a global minimum unless the correct initial guess and learning rate are chosen. For this reason, “vanilla” (or normal) gradient descent is almost always replaced with a modified method in learning problems [4,5].\nThe following demonstrates an animation of the above gradient descent method applied to our data with two different learning rates, one successful, one not. It uses the following animation code and the autograd automatic differentiation library that will be further discussed later:\n\n\nAnimation code\nfrom matplotlib import animation as anim\nfrom matplotlib import gridspec\nfrom mpl_toolkits.mplot3d import Axes3D\n# To display the animations in a jupyer notebook uncomment the following line:\n# %matplotlib notebook\n\ndef animate_steps_2d(xs,loss,xmin=-.1,xmax=2.5,ymin=-1,ymax=3,interval=50):\n    fig = plt.figure(figsize=(10,6),constrained_layout=True)\n    gs = gridspec.GridSpec(ncols=6,nrows=2,figure=fig)\n    ax = fig.add_subplot(gs[:,0:4],projection=\"3d\")\n    ax1 = fig.add_subplot(gs[0,4:])\n    ax2 = fig.add_subplot(gs[1,4:])\n    ax.view_init(47,47)\n    ax.set_xlabel(\"$p_0$\"); ax.set_ylabel(\"$p_2$\"); ax.set_zlabel(\"loss\",rotation=90)\n    ax1.set_xlabel(\"$p_0$\"); ax1.set_ylabel(\"loss\")\n    ax2.set_xlabel(\"$p_1$\"); ax2.set_ylabel(\"loss\")\n\n    xs_arr = np.array(xs)\n    fxs = np.linspace(xmin,xmax,100)\n    fys = np.linspace(ymin,ymax,100)\n    loss_fx = [loss([fxs[j],xs[0][1]]) for j in range(len(fxs))]\n    loss_fy = [loss([xs[0][0],fys[j]]) for j in range(len(fys))]\n    X,Y = np.meshgrid(fxs,fys)\n    Z = np.zeros_like(X)\n    for i in range(X.shape[0]):\n        for j in range(X.shape[1]):\n            Z[i,j] = loss([X[i,j],Y[i,j]])\n    # Add surface plot\n    surf = ax.plot_surface(X,Y,Z,cmap=\"gist_earth\")\n    ax1.set_xlim(np.min(X),np.max(X)); ax1.set_ylim(np.min(Z),np.max(Z))\n    ax2.set_xlim(np.min(Y),np.max(Y)); ax2.set_ylim(np.min(Z),np.max(Z))\n    plot1 = ax.plot(xs[0][0],xs[0][1],loss(xs[0]),zorder=100,color=\"red\",linestyle=\"\",marker=\"o\")[0]\n    plot2 = ax.plot([],[],[],color=\"orange\")[0]\n    # Add flat plots for perspective\n    plot3 = ax1.plot(fxs,loss_fx)[0]\n    plot4 = ax1.scatter(xs[0][0],loss(xs[0]),color=\"red\",s=100,zorder=100)\n    plot5 = ax2.plot(fys,loss_fy)[0]\n    plot6 = ax2.scatter(xs[0][1],loss(xs[0]),color=\"red\",s=100,zorder=100)\n    def anim_func(i):\n        x_loss = loss(xs[i])\n        plot1.set_data_3d(xs[i][0],xs[i][1],x_loss)\n        temp_x1 = [xs[j][0] for j in range(i)]\n        temp_x2 = [xs[j][1] for j in range(i)]\n        temp_losses = [loss(xs[j]) for j in range(i)]\n        plot2.set_data_3d(temp_x1,temp_x2,temp_losses)\n        loss_fx = [loss([fxs[j],xs[i][1]]) for j in range(len(fxs))]\n        loss_fy = [loss([xs[i][0],fys[j]]) for j in range(len(fys))]\n        plot3.set_data(fxs,loss_fx)\n        plot4.set_offsets([xs[i][0],x_loss])\n        plot5.set_data(fys,loss_fy)\n        plot6.set_offsets([xs[i][1],x_loss])\n        plots = [plot1,plot2,plot3,plot4,plot5,plot6]\n        return plots\n\n    tanim = anim.FuncAnimation(fig,anim_func,interval=50,frames=len(xs),blit=True)\n    return tanim\n\n\n\nfrom autograd import grad\nimport autograd.numpy as anp\ndef f_model(p):\n    part1 = anp.exp(-p[0]*xsamples)*(anp.sin((p[0]*xsamples)**3) + anp.sin((p[0]*xsamples)**2) - p[0]*xsamples) \n    part2 = 1/(1 + anp.exp(-p[1]*(xsamples-1)))\n    return part1 + part2\nloss = lambda p: anp.sum((f_model(p) - ysamples)**2)\ngrad_loss = grad(loss) # automatically differentiated\n\n\np0 = np.array([2.1,.2])\nxs = gradient_descent(grad_loss,p0,.005,tol=1e-8,steps=100)[1]\nanimate_steps_2d(xs,loss)\n\n\nAlthough this behavior is somewhat typical of vanilla gradient descent, this model was pathologically chosen to be challenging. The curvature of the loss function for each parameter at the correct parameter values are as follows:\n\n\nPlotting parameter loss curves\nps = np.linspace(-.1,2.5,1000)\nfig,axs = plt.subplots(1,2,sharey=True,figsize=(9,4))\nax1,ax2 = axs\nax1.plot(ps,[loss(np.array([p_i,1])) for p_i in ps])\nax1.set_xlabel(\"$p_0$\"); ax1.set_ylabel(\"Loss\")\nax2.plot(ps,[loss(np.array([1,p_i])) for p_i in ps])\nax2.set_xlabel(\"$p_1$\")\n# plt.xlabel(\"$x$\"); plt.ylabel(\"$y$\"); plt.title(\"Model\")\nplt.show()\n\n\n\n\n\nIn this loss, \\(p_0\\) demonstrates a plethora of local minima which could trap the descent algorithm while \\(p_1\\) has a small gradient which will slow down the convergence. The following methods are meant to simplify the choice of a learning rate while overcoming these specific convergence issues.\n\n\nAdaptive steps\nDue to the challenges of determining a good learning rate (especially in models with many parameters and large variance in loss gradients), many methods have been developed to automatically adjust the \\(\\alpha\\) parameter with each step and for each parameter. One of the most common adaptive algorithms is called adagrad (for adaptive gradient. very creative). Originally developed to provide parameter specific learning rates in sparse problems (in the case that some parameters are only occasionally important) it scales the learning rate by a squared sum of previous gradients:\nadagrad: \\[\n\\begin{align*}\n\\vec{p}^{i+1} &= \\vec{p}^i + v^i \\\\\nv^i &= -\\frac{\\alpha}{\\sqrt{G^i}} \\nabla_p \\mathcal{L}(x;\\vec{p}^i) \\\\\nG^i &= \\sum_{j=0}^i (\\nabla_p \\mathcal{L}(x;\\vec{p}^j))^2\n\\end{align*}\n\\]\n\n\nadagrad code\ndef adagrad(f_p,x0,alpha=.2,tol=1e-12,steps=1000):\n    x = x0\n    xs = [x]\n    # --------- NEW -----------\n    sum_sq_grad = 0\n    for s in range(steps):\n        sum_sq_grad = f_p(x)**2 + sum_sq_grad\n        v_i = -alpha*f_p(x)/np.sqrt(sum_sq_grad)\n    # -------------------------\n        xnew = x + v_i\n        if np.linalg.norm(f_p(xnew)) < tol:\n            print(\"Converged to objective loss gradient below {} in {} steps.\".format(tol,s))\n            return x,xs\n        elif np.linalg.norm(xnew - x) < tol:\n            print(\"Converged to steady state of tolerance {} in {} steps.\".format(tol,s))\n            return x,xs\n        x = xnew\n        xs.append(x)\n    print(\"Did not converge after {} steps (tolerance {}).\".format(steps,tol))\n    return x,xs\n\n\n\np0 = np.array([2.1,.2])\nxs = adagrad(grad_loss, p0,.2,tol=1e-8,steps=100)[1]\nanimate_steps_2d(xs,loss)\n\n However, depending on the problem, this scaled learning rate may slow down convergence considerably. As an adjustment to remove this monotone decreasing learning rate, RMSprop attempts to balance the current gradient with a dampened version of the sum of squares of previous gradients from adagrad:\nRMSprop: \\[\n\\begin{align*}\n\\vec{p}^{i+1} &= \\vec{p}^i + v^i \\\\\nv^i &= -\\frac{\\alpha}{\\sqrt{G^i}} \\nabla_p \\mathcal{L}(x;\\vec{p}^i) \\\\\nG^i &= \\gamma G^{i-1} + (1-\\gamma)(\\nabla_p \\mathcal{L}(x;\\vec{p}^i))^2\n\\end{align*}\n\\]\n\n\nRMSprop code\ndef rmsprop(f_p,x0,gamma=0.9,alpha=0.001,tol=1e-12,steps=1000):\n    x = x0\n    xs = [x]\n    # --------- NEW -----------\n    sum_sq_grad = 0\n    for s in range(steps):\n        sum_sq_grad = (1-gamma)*(f_p(x)**2) + gamma*sum_sq_grad\n        v_i = -alpha*f_p(x)/np.sqrt(sum_sq_grad)\n    # -------------------------\n        xnew = x + v_i\n        if np.linalg.norm(f_p(xnew)) < tol:\n            print(\"Converged to objective loss gradient below {} in {} steps.\".format(tol,s))\n            return x,xs\n        elif np.linalg.norm(xnew - x) < tol:\n            print(\"Converged to steady state of tolerance {} in {} steps.\".format(tol,s))\n            return x,xs\n        x = xnew\n        xs.append(x)\n    print(\"Did not converge after {} steps (tolerance {}).\".format(steps,tol))\n    return x,xs\n\n\n\np0 = np.array([2.1,.2])\nxs = rmsprop(grad_loss, p0,0.2,.05,tol=1e-8,steps=100)[1]\nanimate_steps_2d(xs,loss)\n\n This helps with the challenge of a monotone decreasing learning rate, but it introduces a dampening parameter \\(\\gamma\\) that must be chosen (recommended values are \\(\\alpha = 0.001\\) and \\(\\gamma = 0.9\\)).\n\n\nWith momentum\nThough the previous adaptive methods address the challenge of determining a learning rate, these methods are still likely to terminate in local minima. To address this issue, there are several methods which utilize a concept of “momentum” to propel iterations out of local minima with the hope of landing in the global minimum. This momentum is most simply added by incorporating previous gradients into the current update:\nGradient descent with momentum: \\[\n\\begin{align*}\n    \\vec{p}^{i+1} &= \\vec{p}^i + v^i \\\\\n    v^i &= -\\alpha G^i \\\\\n    G^i &= \\nabla_p \\mathcal{L}(x;\\vec{p}^i) + \\gamma G^{i-1}\n\\end{align*}\n\\]\n\n\nGradient descent with momentum code\ndef gradient_descent_momentum(f_p,x0,gamma,alpha=0.01,tol=1e-12,steps=1000):\n    x = x0\n    xs = [x]\n    # --------- NEW -----------\n    sum_grad = 0\n    for s in range(steps):\n        sum_grad = f_p(x) + gamma*sum_grad\n        v_i = -alpha*sum_grad\n    # -------------------------\n        xnew = x + v_i\n        if np.linalg.norm(f_p(xnew)) < tol:\n            print(\"Converged to objective loss gradient below {} in {} steps.\".format(tol,s))\n            return x,xs\n        elif np.linalg.norm(xnew - x) < tol:\n            print(\"Converged to steady state of tolerance {} in {} steps.\".format(tol,s))\n            return x,xs\n        x = xnew\n        xs.append(x)\n    print(\"Did not converge after {} steps (tolerance {}).\".format(steps,tol))\n    return x,xs\n\n\n\np0 = np.array([2.1,.2])\nxs = gradient_descent_momentum(grad_loss, p0,.9,.005,tol=1e-8,steps=100)[1]\nanimate_steps_2d(xs,loss)\n\n where \\(\\gamma\\) is a momentum parameter that determines how much of previous updates are kept for the current step (\\(0 <= \\gamma <=1\\) where \\(\\gamma = 0\\) includes no momentum).\nHowever, iterations that include this momentum may jump right out of global minima and/or delay convergence. To incorporate a counterbalance to the momentum based on current success (to slow down in the right places), Nesterov acceleration adjusts the gradient according to an approximated step (to see how successful it may be in the future). By so doing, it can effectively reduce or increase the momentum according to the next future iteration:\nNesterov accelerated gradient descent: \\[\n\\begin{align*}\n    \\vec{p}^{i+1} &= \\vec{p}^i + v^i \\\\\n    v^i &= -\\alpha G^i \\\\\n    G^i &= \\nabla_p \\mathcal{L}(x;\\vec{p}^i - \\gamma v^{i-1}) + \\gamma G^{i-1}\n\\end{align*}\n\\]\n\n\nGradient descent with Nesterov acceleration code\ndef gradient_descent_nesterov(f_p,x0,gamma,alpha=0.01,tol=1e-12,steps=1000):\n    x = x0\n    xs = [x]\n    # --------- NEW -----------\n    sum_grad = 0\n    for s in range(steps):\n        sum_grad = f_p(x-gamma*v_i) + gamma*sum_grad\n        v_i = -alpha*sum_grad\n    # -------------------------\n        xnew = x + v_i\n        if np.linalg.norm(f_p(xnew)) < tol:\n            print(\"Converged to objective loss gradient below {} in {} steps.\".format(tol,s))\n            return x,xs\n        elif np.linalg.norm(xnew - x) < tol:\n            print(\"Converged to steady state of tolerance {} in {} steps.\".format(tol,s))\n            return x,xs\n        x = xnew\n        xs.append(x)\n    print(\"Did not converge after {} steps (tolerance {}).\".format(steps,tol))\n    return x,xs\n\n\n\np0 = np.array([2.1,.2])\nxs = gradient_descent_nesterov(grad_loss, p0,.8,.002,tol=1e-8,steps=100)[1]\nanimate_steps_2d(xs,loss)\n\n where again \\(\\gamma\\) is a momentum parameter. Notice that the only adjustment compared to vanilla gradient descent with momentum is calculating the gradient at an approximation of the next parameter values rather than at the current parameters.\n\n\nCombining ideas\nOf course, the ideas of adaptive gradients and momentum both address important issues and are not mutually exclusive, so they can both be used simultaneously (with the downside of adding more parameters to tune). Note that the adaptive step size methods (adagrad,RMSprop) use a sum of squares of the previous gradient while the momentum methods (gradient descent with momentum or Nesterov acceleration) use a sum of the previous gradient. These can be seen as the second moment and first moment of the previous gradients respectively. The Adam (adaptive moment estimation) method uses both of these gradient moments to incorporate both momentum and adaptivity:\nadam: \\[\n\\begin{align*}\n    \\vec{p}^{i+1} &= \\vec{p}^i + v^i \\\\\n    v^i &= -\\frac{\\alpha}{\\sqrt{b^i}}m^i \\\\\n    m^i &= \\beta_1m^{i-1} + (1-\\beta_1)\\nabla_p \\mathcal{L}(x;\\vec{p}^i) \\\\\n    b^i &= \\beta_2b^{i-1} + (1-\\beta_2)(\\nabla_p \\mathcal{L}(x;\\vec{p}^i))^2\n\\end{align*}\n\\]\n\n\nAdam code\ndef adam(f_p,x0,beta1,beta2,alpha=0.01,tol=1e-12,steps=1000):\n    x = x0\n    xs = [x]\n    # --------- NEW -----------\n    sum_grad = 0\n    sum_sq_grad = 0\n    for s in range(1,steps):\n        sum_grad = beta1*sum_grad + (1-beta1)*f_p(x)\n        sum_sq_grad = beta2*sum_sq_grad + (1-beta2)*(f_p(x)**2)\n        v_i = -alpha*sum_grad/np.sqrt(sum_sq_grad)\n    # -------------------------\n        xnew = x + v_i\n        if np.linalg.norm(f_p(xnew)) < tol:\n            print(\"Converged to objective loss gradient below {} in {} steps.\".format(tol,s))\n            return x,xs\n        elif np.linalg.norm(xnew - x) < tol:\n            print(\"Converged to steady state of tolerance {} in {} steps.\".format(tol,s))\n            return x,xs\n        x = xnew\n        xs.append(x)\n    print(\"Did not converge after {} steps (tolerance {}).\".format(steps,tol))\n    return x,xs\n\n\n\np0 = np.array([2.1,.2])\nxs = adam(grad_loss, p0,0.9,0.99,.05,tol=1e-8,steps=100)[1]\nanimate_steps_2d(xs,loss)\n\n Parameters \\(\\beta_1,\\beta_2\\) represent decay rates in incorporating previous moments into the update step.\nAlthough this list is not comprehensive, it demonstrates the reasoning behind the common solutions for the challenges of using gradient descent in learning methods. For a more comprehensive list of recently proposed methods, see [5].\n\n\nAutomatic differentiation\nGradient descent methods rely on computing the gradient of the loss \\(\\nabla_p \\mathcal{L}\\) for a given parameter set \\(\\vec{p}^i\\). For simple models, the gradients can be calculated by hand. However, for models with many nested functions and parameters (neural networks in particular) or methods whose form depends on hyperparameters, we will need an automated method. The “automatic differentiation” method is the solution to these challenges. Though it was developed for neural networks and mainly used there, its breadth of applications is only just becoming apparent. (Consider the Julia language which has worked hard to make automatic differentiation possible everywhere).\nThere are both “forward” and “backward” automatic differentiation methods, but we will consider only the forward which best demonstrates the “automatic” moniker. To do so, consider the first order expansion of two functions at a given point \\(a\\): \\[\n\\begin{align*}\nf(a + \\epsilon) &= f(a) + \\epsilon f'(a) \\\\\ng(a + \\epsilon) &= g(a) + \\epsilon g'(a)\n\\end{align*}\n\\] where \\(\\epsilon\\) is a small perturbation. Basic operations with these functions at this point can then be written as: \\[\n\\begin{align*}\nf + g &= [f(a) + g(a)] + \\epsilon[f'(a) + g'(a)] \\\\\nf - g &= [f(a) - g(a)] + \\epsilon[f'(a) - g'(a)] \\\\\nf \\cdot g &= [f(a) \\cdot g(a)] + \\epsilon[f(a)\\cdot g'(a) + g(a)\\cdot f'(a)] \\\\\nf \\div g &= [f(a) \\div g(a)] + \\epsilon\\left[\\frac{f'(a)\\cdot g(a) + f(a)\\cdot g'(a)}{g(a)^2}\\right]\n\\end{align*}\n\\] The derivatives are then represented by the \\(\\epsilon\\) terms in the above equalities.\nTo implement this on a computer, you can create a new “Dual” number that performs additions, subtractions, multiplications, and divisions with the above operating rules (and can be extended for other functions: \\(\\sin,\\cos,\\exp\\),etc).\n\n\n\n\n\n\nNote\n\n\n\nThis is cumbersome and slow to implement in Python which is why large and complicated libraries have been written in C (tensorflow,pytorch,jax, and others).\nIt can be cleanly and easily implemented in Julia. To see a demonstration of this, see [6].\n\n\nA quick demonstration of a simple implementation of this is as follows [7]. Define a dual number class:\n\nclass DualNumber:\n    def __init__(self, val, der):\n        self.val = val\n        self.der = der\n    def __add__(self, other):\n        if isinstance(other, DualNumber):\n            # DualNumber + DualNumber\n            return DualNumber(self.val + other.val, self.der + other.der)\n        else:\n            # DualNumber + a number\n            return DualNumber(self.val + other, self.der)\n    def __radd__(self, other):\n        # a number + DualNumber\n        return self.__add__(other)\n    def __mul__(self,other):\n        if isinstance(other, DualNumber):\n            # DualNumber * DualNumber\n            return DualNumber(self.val * other.val, self.val*other.der + self.der*other.val)\n        else:\n            # DualNumber * a number\n            return DualNumber(self.val * other, self.der * other)\n    def __rmul__(self,other):\n        # a number * DualNumber\n        return self.__mul__(other)\n    def __pow__(self,power):\n        # DualNumber ^ a number\n            return DualNumber(self.val ** power, self.der * power * (self.val ** (power - 1)))\n    def __repr__(self):\n        # Printing a DualNumber\n        return \"DualNumber({},{})\".format(self.val,self.der)\ndual1 = DualNumber(1,2); dual2 = DualNumber(3,4); other = 5\nprint(dual1,\"+\",dual2,\"=\",dual1+dual2)\nprint(dual1,\"+\",other,\"=\",dual1+other)\nprint(dual1,\"*\",dual2,\"=\",dual1*dual2)\nprint(dual1,\"*\",other,\"=\",dual1*other)\nprint(dual1,\"^\",2,\"=\",dual1**2)\n\nDualNumber(1,2) + DualNumber(3,4) = DualNumber(4,6)\nDualNumber(1,2) + 5 = DualNumber(6,2)\nDualNumber(1,2) * DualNumber(3,4) = DualNumber(3,10)\nDualNumber(1,2) * 5 = DualNumber(5,10)\nDualNumber(1,2) ^ 2 = DualNumber(1,4)\n\n\nThis seems simple, but by using a few rules like this, we can compute simple polynomial derivatives at a point automatically. For example, computing the derivative of \\(f(x) = 3x^3 + 2x + 4\\) at \\(x=2\\). We first initialize the function and the dual number \\((2,1)\\) (\\(1\\) because the derivative of \\(x\\) is \\(1\\)).\n\nf = lambda x: 3*x**3 + 2*x + 4\ndf = lambda x: 9*x**2 + 2\nx = 2; dualx = DualNumber(x,1)\n\nWe then pass the dual number through the polynomial function, unpack the results, and compare the result with the true derivative \\(f'(2)\\):\n\npoly_dual = f(dualx)\ndual_val = poly_dual.val; dual_der = poly_dual.der\ntrue_der = df(x)\nprint(\"True derivative at x=2: \", true_der)\nprint(\"Dual number derivative: \", dual_der)\n\nTrue derivative at x=2:  38\nDual number derivative:  38\n\n\nUsing the rules for dual numbers we provided above, the derivative “automatically” popped out of the polynomial evaluation.\nIn contrast with the forward method, the backward method keeps a log of the operations performed and then uses defined chain rules (similar to how we defined rules for the forward pass) to backtrack from the final output back to the start. This approach is more efficient when the dimension of the gradient is large and that of the output small. Forward evaluation is more efficient when the dimension of the gradient is small and that of the output large.\nAll in all, automatic differentiation is programming with hard-coded differential rules for primitive operations. It can also require keeping track of which operations happen and in what order. Implementing such a method relies heavily on computer science techniques since it boils down to parsing operation calls. This represents one of the clearest differences in the approaches of machine learning to those of statistics or optimization due to its computer language-heavy principles. Through this lens, machine learning could be viewed as “inferential statistics using new tools from computer science for non-traditional problems.”"
  },
  {
    "objectID": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#further-exploration",
    "href": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#further-exploration",
    "title": "Workshop 1: Python set up, machine learning basics, gradient descent, and automatic differentiation",
    "section": "Further Exploration",
    "text": "Further Exploration\n\nEach of the parameters for the gradient descent methods was chosen by hand for the above animations. Try adjusting the starting point and parameters for each to get a feel for how they behave.\nTry splitting the sample data into a training and a testing set. Use the training set and one of the gradient descent methods to fit some parameters, then see how well the model generalizes to the testing set with those parameters.\nTry implementing another gradient descent method from [4] using the given methods as a template.\nAdd the missing subtraction (__sub__, __rsub__) and division (__truediv__, __rtruediv__) methods in the DualNumber class and play around with automatically differentiation functions using those operators (you can use this as a reference). You can also make functions such as sin,cos, or exp that are meant to compute with DualNumbers."
  },
  {
    "objectID": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#appendix",
    "href": "other/mlseminar/fall_2022/workshop1_intro/workshop1_intro.html#appendix",
    "title": "Workshop 1: Python set up, machine learning basics, gradient descent, and automatic differentiation",
    "section": "Appendix",
    "text": "Appendix"
  },
  {
    "objectID": "other/mlseminar/mlseminar.html",
    "href": "other/mlseminar/mlseminar.html",
    "title": "Machine Learning and Optimization Seminar",
    "section": "",
    "text": "The Machine Learning and Optimization is a student-led seminar in the Department of Mathematical Sciences at NJIT. Its goal is to expose the participants to topics in machine learning and optimization by:"
  },
  {
    "objectID": "other/mlseminar/mlseminar.html#fall-2022",
    "href": "other/mlseminar/mlseminar.html#fall-2022",
    "title": "Machine Learning and Optimization Seminar",
    "section": "Fall 2022",
    "text": "Fall 2022\n\nWorkshops\n\n9/15/22: Python set up, machine learning basics, gradient descent, and automatic differentiation - Connor Robertson\n10/6/22: Neural networks - Jake Brusca\n10/13/22: Data-driven model discovery - Connor Robertson\n10/20/22: Convolutional neural networks - Soheil Saghafi\n11/3/22: Recurrent neural networks - Austin Juhl\n12/1/22: Reinforcement learning - Sepideh Saghafi\n\n\n\nPresentations\n\n11/10/22: Recurrent neural networks for beat prediction - Prianka Bose\n12/8/22: Generative adversarial networks - Soheil Saghafi"
  },
  {
    "objectID": "other/mlseminar/mlseminar.html#past-presentations",
    "href": "other/mlseminar/mlseminar.html#past-presentations",
    "title": "Machine Learning and Optimization Seminar",
    "section": "Past Presentations",
    "text": "Past Presentations\n\nSpring 2022\n\nWasserstein GANs Work Because They Fail - Axel Turnquist\nMean-field Theory: Drift and the Mean Drift - Binan Gu\n\n\n\nFall 2021\n\nComputing the Distance Between Probability Measures - Axel Turnquist\nFull Waveform Inversion Using the Wasserstein Metric - Brittany Hamfeldt\nImage Sharpening - Axel Turnquist\nNeural Networks for function approximation and data-driven modeling - Connor Robertson\nOptimal control of systems governed by PDEs with uncertainty - Georg Stadler\nStochastic Temporal Networks - Binan Gu\nTopological Data Analysis Applied to Interaction Networks in Particulate Systems - Lou Kondic\n\n\n\nSpring 2021\n\nSpin Glass and High Dimensional Energy Landscape - Binan Gu\nDiffusion Approximations and Applications in Non-convex Optimization - Binan Gu\nStochastic Gradient Descent and How I Learned to Love the Randomness - Joe McCann\n\n\n\nFall 2020\n\nWhy does stochastic gradient descent work so well? - Axel Turnquist\nInformation Geometry & Learning - Axel Turnquist\nGraph-based Learning Beyond the Paradigm of Neural Networks - Binan Gu\nEffective Dimension in High-Dimensional Problems - Axel Turnquist\nBayesian Statistics and Machine Learning - Gan Luan\nMatrix Completion and Sparse Recovery - Axel Turnquist\nWasserstein GAN - Yixuan Sun\nGraphical Model Selection - Binan Gu\nLearning Frameworks - Axel Turnquist"
  },
  {
    "objectID": "research/active_nematics.html",
    "href": "research/active_nematics.html",
    "title": "Data-driven model discovery for an active nematic system",
    "section": "",
    "text": "Video\n\nSeveral models have been proposed for this system via a continuum “Q-tensor” theory. The models consist of coupled partial differential time-evolution equations for the orientation and velocity of the microtubules (and occasionally the concentration). Though successful in recreating some of the most salient qualitative behavior, there has been some disagreement on the model form and the exact quantitative agreement [2–5].\nThis project aims to provide a data-driven model that can lend insight into the various proposed model forms using the Sparse Identification of Nonlinear Dynamics (SINDy) modeling framework [6]. It involves:\n\nAccurately extracting the orientation, concentration, and velocity of the microtubles in the above video\nGenerating a library of possible terms for each evolution equation via symbolic computation, data fitting, and numerical differentiation of noisy data\nUsing techniques in sparse regression and variable selection to identify the most probable form for the evolution equations\nSimulating the resulting models and comparing the results both qualitatively and quantitatively with the information extracted from the experimental images\n\nThis work was presented at the APS March meeting 2022 and will soon be presented at APS DFD meeting 2022.\n\n\n\n\nReferences\n\n[1] J. Pringle, A. Muthukumar, A. Tan, L. Crankshaw, L. Conway, and J. L. Ross, Microtubule Organization by Kinesin Motors and Microtubule Crosslinking Protein MAP65, Journal of Physics: Condensed Matter 25, 374103 (2013).\n\n\n[2] S. J. DeCamp, G. S. Redner, A. Baskaran, M. F. Hagan, and Z. Dogic, Orientational Order of Motile Defects in Active Nematics, Nature Materials 14, 1110 (2015).\n\n\n[3] A. Doostmohammadi, J. Ignés-Mullol, J. M. Yeomans, and F. Sagués, Active Nematics, Nature Communications 9, 1 (2018).\n\n\n[4] A. U. Oza and J. Dunkel, Antipolar Ordering of Topological Defects in Active Liquid Crystals, New Journal of Physics 18, 093006 (2016).\n\n\n[5] T. Gao, M. D. Betterton, A.-S. Jhang, and M. J. Shelley, Analytical Structure, Dynamics, and Coarse Graining of a Kinetic Model of an Active Fluid, Physical Review Fluids 2, 093302 (2017).\n\n\n[6] S. L. Brunton, J. L. Proctor, and J. N. Kutz, Discovering Governing Equations from Data by Sparse Identification of Nonlinear Dynamical Systems, Proceedings of the National Academy of Sciences 113, 3932 (2016)."
  },
  {
    "objectID": "research/bacteria.html",
    "href": "research/bacteria.html",
    "title": "Predicting bacterial growth in experimental images via recurrent neural networks",
    "section": "",
    "text": "This project focused on predicting the growth of a heterogeneous culture of bacterial strains via experimental images of their interactions and a spatiotemporal convolutional recurrent neural network called PredRNN [1]. Specifically, the network was trained on sequences of images from microwell arrays which show the growth of two mutant strains of Pseudomonas aeruginosa in a single well (one which can kill the other) [2]. A sample of one of these sequences can be seen below. The network then outputs a predicted sequence of subsequent images, which we compared with the true images via popular image metrics such as Learned Perceptual Image Patch Similarity (LPIPS) as well as with biological metrics such as the number and size of colonies of each strain. The results of this work can be found in this preprint [3].\n\n\n\nThis same technique was also applied to accelerate the results of an agent based model of the same system which can be found in this preprint [4].\n\n\n\n\nReferences\n\n[1] Y. Wang, H. Wu, J. Zhang, Z. Gao, J. Wang, P. Yu, and M. Long, PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive Learning, IEEE Transactions on Pattern Analysis and Machine Intelligence 1 (2022).\n\n\n[2] A. C. Timm, M. C. Halsted, J. L. Wilmoth, and S. T. Retterer, Assembly and Tracking of Microbial Community Development Within a Microwell Array Platform, JoVE (Journal of Visualized Experiments) e55701 (2017).\n\n\n[3] C. Robertson, J. L. Wilmoth, S. Retterer, and M. Fuentes-Cabrera, Performing Video Frame Prediction of Microbial Growth with a Recurrent Neural Network, (2022).\n\n\n[4] J. Sakkos et al., Investigating the Growth of an Engineered Strain of Cyanobacteria with an Agent-Based Model and a Recurrent Neural Network, bioRxiv (2021)."
  },
  {
    "objectID": "research/research.html",
    "href": "research/research.html",
    "title": "Research",
    "section": "",
    "text": "This section contains various overviews of the research projects that I have worked on or which I am currently working on. They are high level overviews of the project scope as well as references to papers and results."
  },
  {
    "objectID": "research/research.html#projects",
    "href": "research/research.html#projects",
    "title": "Research",
    "section": "Projects",
    "text": "Projects\n\nData-driven discovery of a PDE model for an active nematic system\nPredicting bacterial growth in experimental images using recurrent neural networks"
  },
  {
    "objectID": "teaching/math110/math110.html",
    "href": "teaching/math110/math110.html",
    "title": "Math 110 - Precalculus",
    "section": "",
    "text": "This website section contains some resources for the Fall 2022 Math 110 Sections 11 and 13 at NJIT. Hopefully, the notes, problems, and supplementary plots/videos/animations can help deepen understanding or act as a reference for review."
  },
  {
    "objectID": "teaching/math110/math110.html#polynomial-functions",
    "href": "teaching/math110/math110.html#polynomial-functions",
    "title": "Math 110 - Precalculus",
    "section": "Polynomial functions",
    "text": "Polynomial functions\nMotivation: We’d like to understand functions that involve exponents because they show up in innumerable places in our life\n\nPolynomials are equations with several terms involving different “orders” of exponents (which are whole number exponents i.e. not fractions). A polynomial function can be written as: \\[\nP(x) = a_nx^n + a_{n-1}x^{n-1} + \\ldots + a_1x^1 + a_0x^0\n\\] where \\(a_n,\\ldots,a_0\\) are the “coefficients” of the many terms \\(x^j\\) for \\(j=0,\\ldots,n\\).\nConstant: A polynomial where \\(n=0\\)\nLinear: A polynomial where \\(n=1\\)\nQuadratic: A polynomial where \\(n=2\\)\nCubic: A polynomial where \\(n=3\\)\nQuartic: A polynomial where \\(n=4\\)\n\n\nNonpolynomial Functions\n\nFunctions that don’t have whole number exponents or exponents at all or are fractions of polynomials\nExamples:\n\n\\(f(x) = |x+2|\\)\n\\(f(x) = \\sqrt{x}-1\\)\n\\(f(x) = x^{4/5}\\)\n\\(f(x) = \\frac{x+1}{x-2}\\)\n\n\n\n\nLeading order test\n\nThe largest exponent determines how the polynomial behaves for very large or very small values of \\(x\\)\nYou can tell the shape of a plotted polynomial by its largest exponent\n\nLargest exponent is even: As \\(x\\) gets very large or very negative, the polynomial either gets very large or very negative. See book.\nLargest exponent is odd: As \\(x\\) gets very large or very negative, one side of the polynomial gets very large and the other very negative. See book.\n\n\n\n\nFinding zeros of polynomials\n\nOnce a polynomial is factored, it is very easy to find its zeros\n\nExample:\n\nFor function \\[g(x) = x^2 - 2x - 8 = (x + 2)(x-4)\\] there are zeros at \\(x=-2,4\\)\nThis is easy to check:\n\nIf \\(x=-2\\): \\[g(-2) = (-2 + 2)(-2 - 4) = 0(-2-4) = 0\\]\nIf \\(x=4\\): \\[g(4) = (4 + 2)(4 - 4) = (4 + 2)0 = 0\\]\n\n\n\nThe multiplicity of a zero or “root” of the polynomial function is the number of times that number appears in the factored form\n\nExample:\n\nFor function \\[g(x) = x^2 - 8x + 16 = (x-4)(x-4)\\] which means it has only one root of \\(x=4\\). But, the root appears twice in the factored form, so the multiplicity of the root is 2."
  },
  {
    "objectID": "teaching/math110/math110.html#problems",
    "href": "teaching/math110/math110.html#problems",
    "title": "Math 110 - Precalculus",
    "section": "Problems",
    "text": "Problems"
  },
  {
    "objectID": "teaching/math111/quizzes/quiz1.html",
    "href": "teaching/math111/quizzes/quiz1.html",
    "title": "Quiz 1 - Limits and rate of change",
    "section": "",
    "text": "Find \\[\n\\lim_{t\\rightarrow 0} \\frac{\\tan(t)\\sec(t)}{3t}\n\\]\n\n\n\n\\[\n\\begin{align*}\n\\lim_{t\\rightarrow 0} \\frac{\\tan(t)\\sec(t)}{3t} &= \\frac{1}{3}\\lim_{t\\rightarrow 0} \\frac{\\sin(t)}{\\cos(t)} \\times \\frac{1}{\\cos(t)} \\times \\frac{1}{t} \\\\\n&= \\frac{1}{3} \\lim_{t\\rightarrow 0} \\cancelto{1}{\\frac{\\sin(t)}{t}} \\times \\frac{1}{\\cos^2(t)} \\\\\n&= \\frac{1}{3} \\lim_{t\\rightarrow 0} \\frac{1}{\\cos^2(t)} \\\\\n&= \\boxed{\\frac{1}{3}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "teaching/math111/quizzes/quiz1.html#problem-2",
    "href": "teaching/math111/quizzes/quiz1.html#problem-2",
    "title": "Quiz 1 - Limits and rate of change",
    "section": "Problem 2",
    "text": "Problem 2\n\nQuestion\nFor function \\(y = f(x) = 3x^2 + 1\\):\n\nFind the rate of change \\(\\frac{\\Delta y}{\\Delta x}\\)\nFind the average rate of change over intervals \\([2,3]\\) and \\([-1,1]\\)\n\n\n\nSolution\n\na.\n\\[\n\\begin{align*}\n\\frac{\\Delta y}{\\Delta x} &= \\frac{f(x + \\Delta x) - f(x)}{x + \\Delta x - x} \\\\\n&= \\frac{3(x+\\Delta x)^2 + 1 - (3x^2 + 1)}{\\Delta x} \\\\\n&= \\frac{\\cancel{3x^2} + 6x\\cancel{(\\Delta x)} + 3(\\Delta x)^\\cancel{2} + \\cancel{1}- \\cancel{ 3x^2} -\\cancel{1} }{\\cancel{\\Delta x}} \\\\\n&= \\boxed{6x + 3(\\Delta x)}\n\\end{align*}\n\\]\n\n\nb.\nFor \\([2,3]\\): \\[\n\\begin{align*}\n\\frac{f(x_2) - f(x_1)}{x_2 - x_1} &= \\frac{f(3) - f(2)}{3 - 2} \\\\\n&= \\frac{3(3)^2 + 1 - (3(2)^2 + 1)}{1} \\\\\n&= 27 - 12 = \\boxed{15}\\\\\n\\end{align*}\n\\] For \\([-1,1]\\): \\[\n\\begin{align*}\n\\frac{f(x_2) - f(x_1)}{x_2 - x_1} &= \\frac{f(1) - f(-1)}{1 + 1} \\\\\n&= \\frac{3(1)^2 + 1 - (3(-1)^2 + 1)}{2} \\\\\n&= \\frac{0}{2} = \\boxed{0}\\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "teaching/math111/quizzes/quiz2.html",
    "href": "teaching/math111/quizzes/quiz2.html",
    "title": "Quiz 2 - Limits and rate of change",
    "section": "",
    "text": "Show that the graph of \\(f(x) = 3x^2 + 5x - 11 = 0\\) has a solution between \\(x=1\\) and \\(x=2\\). State which theorem you used.\n\n\n\nSince we know that \\(f(x)\\) is a polynomial and thus continous, we can use the intermediate value theorem to show that there exists a root between the points. To do so we need to show that the function is above the x-axis at one of the endpoints and below at the other: \\[\n\\begin{align*}\nf(1) &= 3(1)^2 + 5(1) - 11 = 3 + 5 - 11 = -3 < 0 \\\\\nf(2) &= 3(2)^2 + 5(2) - 11 = 12 + 10 - 11 = 11 > 0\n\\end{align*}\n\\]"
  },
  {
    "objectID": "teaching/math111/quizzes/quiz2.html#problem-2",
    "href": "teaching/math111/quizzes/quiz2.html#problem-2",
    "title": "Quiz 2 - Limits and rate of change",
    "section": "Problem 2",
    "text": "Problem 2\n\nQuestion\nFind constants \\(a,b\\) so that the function given below is continuous for all \\(x\\): \\[\nf(x) = \\begin{cases}\nx^2 + 3 & x<2 \\\\\na & x = 2 \\\\\nax+b & x > 2\n\\end{cases}\n\\]\n\n\nSolution\nFirst, we need to make sure that the left most part of the function connects with the center part: \\[\n\\begin{align*}\na &= x^2 + 3 \\text{ at }x=2 \\\\\n&= (2)^2 + 3 \\\\\n\\Aboxed{a &= 7}\n\\end{align*}\n\\] Next, we match the center part to the rightmost part: \\[\n\\begin{align*}\na &= ax + b\\text{ at }x=2 \\\\\n7 &= 7(2) + b \\\\\nb &= 7 - 14 \\\\\n\\Aboxed{b &= -7}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "teaching/math111/math111.html",
    "href": "teaching/math111/math111.html",
    "title": "Math 111 - Calculus I",
    "section": "",
    "text": "This section contains some resources for the Fall 2022 Math 111 Section 23 at NJIT. Hopefully, the notes, problems, and supplementary plots/videos/animations can help deepen understanding or act as a reference for review."
  },
  {
    "objectID": "teaching/math111/math111.html#quiz-solutions",
    "href": "teaching/math111/math111.html#quiz-solutions",
    "title": "Math 111 - Calculus I",
    "section": "Quiz Solutions",
    "text": "Quiz Solutions\n\nQuiz 1\nQuiz 2"
  },
  {
    "objectID": "teaching/math111/math111.html#notes",
    "href": "teaching/math111/math111.html#notes",
    "title": "Math 111 - Calculus I",
    "section": "Notes",
    "text": "Notes\n\nLimits and Continuity\nMotivation: People were interested in the speed and direction of planets at any moment in time. So, they wanted to know if they could calculate that by measuring the path of the planets. We can use a concept called “limits” to find this speed and direction.\n\nCalculus relates the rate of changes of things. i.e. how quickly does water empty out of a barrel is a ratio of the rate of change of the water relative to the rate of change of time.\n\n\nAverage and Instantaneous Rates of Change\n\nAverage speed: Divide the distance traveled by the time elapsed\nInstantaneous speed: The average speed over an infinitely small amount of time\nSecant line: A line connecting two points on a curve\nAs the two points of a secant line get closer and closer, the slope of the secant approaches the instantaneous velocity\nTangent line: A line that only touches one point on a line\nThe slope of a curve at a point \\(x\\) is the slope of the tangent line that passes through only \\(x\\)\nFor a curve that represents a quantity (y-axis) over time (x-axis), the slope of the tangent line at a point \\(t\\) in time is the instantaneous velocity (or rate of change of time) at \\(t\\)\nFormula for secant line / average velocity from time \\(t_1\\) to \\(t_2\\) where function \\(f(t)\\) is the position at time \\(t\\) and \\(\\Delta\\) represents “change in …”: \\[\n\\boxed{\\frac{\\Delta f}{\\Delta t}} = \\frac{f(t_2) - f(t_1)}{t_2 - t_1} = \\frac{f(t+h) - f(t)}{t+h - t} = \\boxed{\\frac{f(t+h) - f(t)}{h}}\n\\]\n\n\n\nHelpful animation\nAnimation of Figure 2.6 from the book.\n\n\n\n\nProblems"
  },
  {
    "objectID": "teaching/math340/Lab1_matlab_taylor_series/Lab1_Examples.html",
    "href": "teaching/math340/Lab1_matlab_taylor_series/Lab1_Examples.html",
    "title": "Connor Robertson",
    "section": "",
    "text": "Lab Instructor: Connor Robertson\n\n\nHere are a few basic calculations and constructions that you will need to use throughout the course for building arrays of numbers. Take note of these constructions as they will be useful for the entire course\n\n% a row vector, X=(0 1 2 3) can be written three ways:\n\n% here it is written using brackets\nX = [0 1 2 3]\n\n\nX =\n\n     0     1     2     3\n\n\n\n\n% including ; at the end of the line will suppress the output (it will\n% still do the command but not print the variable:\nX = [0 1 2 3];\n\n% Here it is written in the form X=linspace(a,b,n) where\n% a is the first point, b is the last and n is the number\n% of equally spaced points\nX = linspace(0, 3, 4)\n\n\nX =\n\n     0     1     2     3\n\n\n\n\n% linspace is a function that Matlab includes by default (it is in the\n% Matlab standard library)\n\n% Here it is written in the form X=a:delta:b where\n% a is the first point, b is the last and delta is the \n% distance between each point\nX=0:1:3"
  },
  {
    "objectID": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html",
    "href": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html",
    "title": "Lab 1 - Brief Introduction to Matlab",
    "section": "",
    "text": "Here are a few basic calculations and constructions that you will need to use throughout the course for building arrays of numbers. Take note of these constructions as they will be useful for the entire course.\n\n\nA row vector, X=(0 1 2 3) is commonly written in three ways:\n1. Using brackets:\nX=[0 1 2 3]\nIf ; is included at the end of the line, the output will be supressed. The command will still be executed, but nothing will be printed.\nX=[0 1 2 3];\n2. Using the linspace function:\nX=linspace(0, 3, 4)\nThis gives 4 equally spaced points between and including 0 and 3 as shown above. linspace is a function included in the Matlab standard library i.e. it is always available.\n3. In the form a:step:b:\nX=0:1:3\nThis will give all points between and including 0 to 3 with step size 1 between each point. It can also be written as X=0:3 which uses the default step size 1.\n\n\n\nOnce we have these arrays, we can apply an operation to each element in the array. For example, to compute \\(Y = [e^0, e^2, e^2, e^3]\\), we use the Matlab standard library function exp for exponential:\nY=exp(X)\nOr to apply sin to each element of the array:\nS=sin(X)\nOr to make an array Q with the square root to each element of the array X:\nQ=sqrt(X)\n\n\n\nTo create a \\(2\\times2\\) identity matrix:\nId=[1 0; 0 1]\nNote that the ; in the array definition marks the end of a row. There is also a Matlab standard library function eye that can be used as:\nId2=eye(2)\nA \\(4\\times 4\\) identity matrix is then:\nId4=eye(4)\nTo make a length 4 column vector (4 rows, 1 column) of all zeros, we can use the standard library zeros function:\nz = zeros(4,1)\nThis can be extended to a \\(4\\times4\\) matrix of all zeros:\nZ=zeros(4,4)\nOr a \\(3\\times3\\) matrix of all ones:\nW=ones(3,3)\n\n\n\nIf we wanted to compute the matrix-vector product of Id4 with our previous row vector X, we would first need to transpose X into a column vector. This can be done with either the standard library transpose function or the operator ':\nY=Id4 * X'\nor\nY=Id4 * transpose(X)\nFailing to transpose will give an error:\nId4 * X"
  },
  {
    "objectID": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-2-common-operations",
    "href": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-2-common-operations",
    "title": "Lab 1 - Brief Introduction to Matlab",
    "section": "Example 2: Common operations",
    "text": "Example 2: Common operations\nIn Matlab, the * operator means “dot product” when working with matrices and vectors. If we instead wish to apply a multiplication operation to each element of an array, we preface the operation with a dot, i.e. .*. This elementwise operator syntax with an additional period extends to division and exponents as ./ and .^ respectively. Observe the difference between the products A*B and A.*B in the following examples:\nA=[1 0; 0 1]\nB=[0 1; 1 0]\nx = [1 ; 0]\nThe dot product is A*B:\nA*B\nA * x\nThe elementwise product is A.*B:\nA.*B\nThis product is the product of each element of A with each corresponding element of B."
  },
  {
    "objectID": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-3-plotting-in-matlab",
    "href": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-3-plotting-in-matlab",
    "title": "Lab 1 - Brief Introduction to Matlab",
    "section": "Example 3: Plotting in Matlab",
    "text": "Example 3: Plotting in Matlab\nTo plot a line in Matlab, you will need to pass in arrays of \\(x\\) and \\(y\\) positions to the standard library plot function. These positions will be used as \\((x,y)\\) coordinates through which the line will pass. In this example we will define our function using an inline (or anonymous) function. More complicated functions can be found at the bottom of this page.\nFirst, create the function we would like to plot:\nf=@(x) x.^3;\nThis is now a function variable f to which we can pass in a value x and it will compute \\(x^3\\). We use .^ so that we can pass an array x into the function. We can now create a set of 1000 equally spaced x values between -2 and 2:\nX =linspace(-2, 2, 1000);\nand cube each of them using our function f to get an array of 1000 y points:\nY=f(X);\nWe can now pass X and Y as our \\(x\\) and \\(y\\) positions to the plot function to get a line that passes through each \\((x,y)\\) in order.\nplot(X,Y)\nThere are several additional parameters we can pass into the plot function to change the line style and color of the lines. Judgement should be used to determine which plot options to use to make your results of your work clear.\nWe can now create a new figure (a new plotting area with no lines on it) and plot our points with several additional decorations:\nfigure()\nplot(X,Y,'r','LineWidth',1); % 'r' => red line\n\nhold on\nplot(X,X);\n\ngrid on\n\naxis([-1 1 -2 2]);\n\nxlabel('x','fontsize',14); \nylabel('f(x)','fontsize',14);\n\ntitle('Plot example',...\n    'fontsize',14);\n\nlegend('x^3', 'x');\nThe 'LineWidth' marks that the width will be changed and 1 is the selected line width. The hold on command will keep the current figure for all new plots and plotting commands until a new figure is created with figure() or the hold is removed with hold off. This allows more lines to be added to the current figure. grid on turns on grid lines for the figure and axis is a function to determine the limits of the x and y axes. xlabel and ylabel are functions for labeling the figure axes and title is a function to give the figure a title. Note that the ... tells Matlab that the function inputs are continued on the next line. The legend function allows for annotating the plots in the figure in the order they were plotted."
  },
  {
    "objectID": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-4-control-flow",
    "href": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-4-control-flow",
    "title": "Lab 1 - Brief Introduction to Matlab",
    "section": "Example 4: Control flow",
    "text": "Example 4: Control flow\nOne standard programming construct is that of a “for loop.” The following simple example shows how to implement a for loop to add the numbers between 1 and N. We will find the sum of the first 50 numbers\nN=50;\n\n% Initialize the sum variable as 0. We are going to add to this\nsumN = 0;\nfor i=1:N\n    \n    % In each iteration we will add the new number i to our sum\n    sumN = sumN+i;\nend\ndisp is the matlab function for “displaying” or printing a value or array. num2str is the matlab function to convert a number to a “string” which is a datatype meant for sequences of letters. This is especially useful for printing by combining different strings as shown below:\nresult = ['The sum of the first ' num2str(N) ' numbers is ' num2str(sumN)];\ndisp(result)\nThis algorithm is also packaged as a Matlab function SumN at the bottom of this file. In this course, all algorithms will be written as a function so they can be easily reused. However, all functions in Matlab scripts must be placed at the end of the file, so scroll down to see the function SumN.\ntotal=SumN(N);\nresult2 = ['The Sum is still ', num2str(total)];\ndisp(result2)"
  },
  {
    "objectID": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-5-a-simple-numerical-method-taylor-series",
    "href": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#example-5-a-simple-numerical-method-taylor-series",
    "title": "Lab 1 - Brief Introduction to Matlab",
    "section": "Example 5: A simple numerical method (Taylor series)",
    "text": "Example 5: A simple numerical method (Taylor series)\nAs an application of the examples above, the following shows how to approximate the \\(\\sin\\) function at a point \\(x\\)using the Taylor series of \\(\\sin\\) (centered at 0). This makes use of for loops as demonstrated above.\nIf we consider \\(x=1\\) and use the first \\(N=20\\) terms in the Taylor series, we initialize our variables:\nx = 1;\nN = 20;\nWe then initialize a variable my_sin1 in which we will store the result and use the for loop to add each term evaluated at \\(x=1\\) to the variable:\nmy_sin1 = 0;\nfor n=0:N\n    new_term = (-1)^n * (x^(2*n+1)) / factorial(2*n + 1);\n    my_sin1 = my_sin1 + new_term;\nend\nWe can compare our approximation with Matlab’s approximation of \\(\\sin(1)\\) by comparing it with the standard library function sin:\ndisp(\"My answer:\")\ndisp(my_sin1)\ndisp(\"Matlab's answer:\")\ndisp(sin(1))\nA function that takes as inputs x and N and computes the taylor series approximation of \\(\\sin\\) as we just have for x=1,N=20 can be seen at the bottom of this file under the name my_sin. We can verify that it gives the same result:\ndisp(my_sin(1, 20))"
  },
  {
    "objectID": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#functions",
    "href": "teaching/math340/Lab1_matlab_taylor_series/Lab1_matlab_intro.html#functions",
    "title": "Lab 1 - Brief Introduction to Matlab",
    "section": "Functions",
    "text": "Functions\nfunction [output] = SumN(input)\n    % The names \"input\" and \"output\" are chosen to make it clear how this\n    % function works. The names don't matter as long as they are consistent.\n    N=input;\n    sum=0;\n    for i=1:N\n        % In each iteration we will add the new number to our sum\n        sum=sum+i;\n    end\n    output=sum;\nend;\nfunction [answer] = my_sin(x, N)\n    answer = 0;\n    for n=0:N\n        new_term = (-1)^n * (x^(2*n+1)) / factorial(2*n + 1);\n        answer = answer + new_term;\n    end\nend"
  },
  {
    "objectID": "teaching/teaching.html",
    "href": "teaching/teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "This section contains various supplemental resources for the students in my classes in the Department of Mathematical Sciences at NJIT. They are organized by class."
  },
  {
    "objectID": "teaching/teaching.html#classes",
    "href": "teaching/teaching.html#classes",
    "title": "Teaching",
    "section": "Classes",
    "text": "Classes\n\nMath 110 - Precalculus\nMath 111 - Calculus 1\nMath 340 - Applied Numerical Methods"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Connor Robertson",
    "section": "",
    "text": "On this site you can find my CV, my LinkedIn and Github profiles, and some other little tidbits for teaching, research, seminars, and general exploration."
  }
]