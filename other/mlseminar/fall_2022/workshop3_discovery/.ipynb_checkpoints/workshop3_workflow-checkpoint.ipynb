{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936f1104",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import flax.linen as nn\n",
    "import sympy as sp\n",
    "from itertools import combinations_with_replacement\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.metrics as met\n",
    "import sklearn.feature_selection as fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52816932",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data(data_path, batch_size):\n",
    "    # Load data\n",
    "    raw_data = np.load(data_path)\n",
    "    h = raw_data[\"h\"].astype(jnp.float32)\n",
    "    x = raw_data[\"x\"].astype(jnp.float32)\n",
    "    t = raw_data[\"t\"].astype(jnp.float32)\n",
    "\n",
    "    # Mean center, std center data\n",
    "    h = (h - jnp.mean(h)) / jnp.std(h)\n",
    "    x = (x - jnp.mean(x)) / jnp.std(x)\n",
    "    t = (t - jnp.mean(t)) / jnp.std(t)\n",
    "\n",
    "    # Load data in batches\n",
    "    data = []\n",
    "    index_list = list(np.ndindex(h.shape))\n",
    "    for ind in range(0,len(index_list),batch_size):\n",
    "        inds = index_list[ind:ind+batch_size]\n",
    "        xts = np.array([[x[j],t[i]] for i,j in inds])\n",
    "        hs = np.array([[h[i,j]] for i,j in inds])\n",
    "        if len(xts) == batch_size:\n",
    "            data.append((xts,hs))\n",
    "    return h,x,t,data\n",
    "h,x,t,data = load_data(\"data/simple_wave.npz\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenDict({\n",
      "    params: {\n",
      "        Dense_0: {\n",
      "            bias: (60,),\n",
      "            kernel: (2, 60),\n",
      "        },\n",
      "        Dense_1: {\n",
      "            bias: (12,),\n",
      "            kernel: (60, 12),\n",
      "        },\n",
      "        Dense_2: {\n",
      "            bias: (1,),\n",
      "            kernel: (12, 1),\n",
      "        },\n",
      "    },\n",
      "})\n",
      "Validation loss step 0: 1.0899022817611694\n",
      "Validation loss step 100: 0.164273202419281\n",
      "Validation loss step 200: 0.0930459052324295\n"
     ]
    }
   ],
   "source": [
    "# Flax style\n",
    "class MyNet(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(60)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(12)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(1)(x)\n",
    "        return x\n",
    "\n",
    "rng1,rng2 = jax.random.split(jax.random.PRNGKey(42))\n",
    "model = MyNet()\n",
    "init_data = jax.random.normal(rng1,(2,))\n",
    "params = model.init(rng2,init_data)\n",
    "print(jax.tree_util.tree_map(lambda x: x.shape, params))\n",
    "\n",
    "# Training\n",
    "@jax.jit\n",
    "def mse(params,input,targets):\n",
    "    def squared_error(x,y):\n",
    "        pred = model.apply(params,x)\n",
    "        return jnp.mean((y - pred)**2)\n",
    "    return jnp.mean(jax.vmap(squared_error)(input,targets),axis=0)\n",
    "\n",
    "tx = optax.adam(1e-2)\n",
    "opt_state = tx.init(params)\n",
    "loss_grad_fn = jax.value_and_grad(mse)\n",
    "\n",
    "epochs = 1000\n",
    "all_x = jnp.array([data[i][0] for i in range(len(data))])\n",
    "all_y = jnp.array([data[i][1] for i in range(len(data))])\n",
    "for i in range(1000):\n",
    "    x_batch = data[i%len(data)][0]\n",
    "    y_batch = data[i%len(data)][1]\n",
    "    loss_val, grads = loss_grad_fn(params, x_batch, y_batch)\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    if i % 100 == 0:\n",
    "        valid_loss = mse(params,all_x,all_y)\n",
    "        print(\"Validation loss step {}: {}\".format(i,valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c5961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "\n",
    "X,T = jnp.meshgrid(x,t)\n",
    "xt_points = jnp.vstack([X.flatten(),T.flatten()]).T\n",
    "hhat = model.apply(params,xt_points).reshape(X.shape)\n",
    "diff = np.sqrt((h - hhat)**2)\n",
    "# hhat_t = h_t.reshape(X.shape)\n",
    "# hhat_t = np.array(term_matrix[diff_terms[1]]).reshape(X.shape)\n",
    "\n",
    "def animate_data(x,t,data_list,labels):\n",
    "    fig = plt.figure()\n",
    "    plots = []\n",
    "    for i in range(len(data_list)):\n",
    "        plot = plt.plot(x,data_list[i][0,:],label=labels[i])[0]\n",
    "        plots.append(plot)\n",
    "\n",
    "    def anim_func(j):\n",
    "        for i in range(len(plots)):\n",
    "            plots[i].set_ydata(data_list[i][j,:])\n",
    "        # p1.set_ydata(h[j,:])\n",
    "        # p2.set_ydata(hhat[j,:])\n",
    "        # p3.set_ydata(hhat_t[j,:])\n",
    "\n",
    "    plt.legend()\n",
    "    approx_anim = anim.FuncAnimation(fig, anim_func, range(len(t)))\n",
    "    plt.show()\n",
    "\n",
    "animate_data(x,t,[h,hhat,diff],[\"h\",\"hhat\",\"L2 err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test grad\n",
    "t_i = 0.3\n",
    "x_i = 0.3\n",
    "def model_for_diff(x,t):\n",
    "    new_x = jnp.array([x,t])\n",
    "    return model.apply(params, new_x)[0]\n",
    "\n",
    "def model_in_x(x):\n",
    "    new_x = jnp.array([x,t_i])\n",
    "    return model.apply(params, new_x)[0]\n",
    "\n",
    "def model_in_t(t):\n",
    "    new_t = jnp.array([x_i,t])\n",
    "    return model.apply(params, new_t)[0]\n",
    "\n",
    "test_x = 0.3\n",
    "print(model_in_x(test_x))\n",
    "jax.grad(model_in_x)(test_x)\n",
    "jax.grad(model_for_diff,0)(test_x,t_i)\n",
    "jax.grad(jax.grad(model_in_x))(test_x)\n",
    "jax.grad(jax.grad(jax.grad(model_in_x)))(test_x)\n",
    "\n",
    "# Apply to all x\n",
    "jax.lax.map(jax.grad(model_in_x), X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7408d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symoblic library\n",
    "x_sym,t_sym = sp.symbols(\"x t\")\n",
    "h_sym = sp.Function(\"h\")\n",
    "\n",
    "# Make library\n",
    "max_poly_order = 4\n",
    "max_diff_order = 4\n",
    "\n",
    "# diff_terms = [sp.diff(h_sym(x_sym,t_sym), x_sym, i) for i in range(max_diff_order+1)]\n",
    "diff_terms = [h_sym(x_sym,t_sym)] + [sp.Function(str(h_sym)+\"_\"+(i*str(x_sym)))(x_sym,t_sym) for i in range(1,max_diff_order+1)]\n",
    "\n",
    "# Differentiate model and store results with autodiff\n",
    "diff_term_values = {}\n",
    "for i in range(max_diff_order+1):\n",
    "    diff_func = model_for_diff\n",
    "    for _ in range(i):\n",
    "        diff_func = jax.grad(diff_func, 0)\n",
    "    def unpack_diff_func(x):\n",
    "        new_x,new_t = x\n",
    "        return diff_func(new_x,new_t)\n",
    "    diff_term_values[diff_terms[i]] = np.array(jax.lax.map(unpack_diff_func, xt_points))\n",
    "\n",
    "# Construct terms\n",
    "term_values = {}\n",
    "for po in range(max_poly_order+1):\n",
    "    if po == 0:\n",
    "        term = sp.core.numbers.One()\n",
    "        term_values[term] = np.ones(xt_points.shape[0])\n",
    "    else:\n",
    "        combos = combinations_with_replacement(diff_terms,po)\n",
    "        for combo in combos:\n",
    "            term = 1\n",
    "            temp_term_value = 1\n",
    "            for combo_term in combo:\n",
    "                term *= combo_term\n",
    "                temp_term_value *= diff_term_values[combo_term]\n",
    "            term_values[term] = temp_term_value\n",
    "\n",
    "# Time derivative\n",
    "def unpack_diff_func(x):\n",
    "    new_x,new_t = x\n",
    "    return jax.grad(model_for_diff,1)(new_x,new_t)\n",
    "\n",
    "# term_values[sp.Function(str(h_sym)+\"_\"+str(t_sym))] = jax.lax.map(unpack_diff_func, xt_points)\n",
    "h_t = -np.array(jax.lax.map(unpack_diff_func, xt_points))\n",
    "h_t_term = sp.Function(\"h_t\")(x_sym,t_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_matrix = pd.DataFrame(term_values)\n",
    "ols = lm.LinearRegression()\n",
    "ols.fit(term_matrix,h_t)\n",
    "print(\"R^2: {}\".format(met.r2_score(ols.predict(term_matrix), h_t)))\n",
    "\n",
    "def forward_r2_select(A,b,num_terms=4):\n",
    "    for i in range(1,num_terms+1):\n",
    "        sfs = fs.SequentialFeatureSelector(\n",
    "            lm.LinearRegression(),\n",
    "            n_features_to_select=i,\n",
    "            scoring=met.make_scorer(met.r2_score)\n",
    "        )\n",
    "        new_A = sfs.fit_transform(A,b)\n",
    "        new_ols = sfs.estimator\n",
    "        new_ols.fit(new_A,b)\n",
    "        print(\"Equation:\")\n",
    "        # print(\"h_t(x,t) = \")\n",
    "        feat_names = sfs.get_feature_names_out(A.columns)\n",
    "        eq_rhs = 0\n",
    "        for name,coef in zip(feat_names,new_ols.coef_):\n",
    "            # print(\"    {} {}\".format(round(coef,2),name))\n",
    "            # eq_rhs = eq_rhs + round(coef,2)*name\n",
    "            eq_rhs = eq_rhs + coef*name\n",
    "        eq_expr = sp.Eq(h_t_term, eq_rhs)\n",
    "        print(sp.printing.latex(eq_expr))\n",
    "        print(\"R^2: {}\".format(met.r2_score(new_ols.predict(new_A),b)))\n",
    "        print()\n",
    "\n",
    "forward_r2_select(term_matrix,h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49681afa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "lasso = lm.Lasso(10)\n",
    "lasso.fit(term_matrix,h_t)\n",
    "lasso.coef_"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
